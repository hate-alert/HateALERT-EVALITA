{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from collections import Counter\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "from sklearn.metrics import make_scorer, f1_score, accuracy_score, recall_score, precision_score, classification_report, precision_recall_fscore_support\n",
    "import itertools\n",
    "from string import punctuation\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from scipy.sparse import hstack\n",
    "import pickle\n",
    "# from multilabel_data_handler import get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/binny/anaconda3/envs/punyajoy-nogpu/lib/python3.5/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn import neighbors\n",
    "from sklearn import ensemble\n",
    "from sklearn import neural_network\n",
    "from sklearn import linear_model\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# file used to write preserve the results of the classfier\n",
    "# confusion matrix and precision recall fscore matrix\n",
    "\n",
    "def plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=True):\n",
    "    \"\"\"\n",
    "    given a sklearn confusion matrix (cm), make a nice plot\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
    "\n",
    "    target_names: given classification classes such as [0, 1, 2]\n",
    "                  the class names, for example: ['high', 'medium', 'low']\n",
    "\n",
    "    title:        the text to display at the top of the matrix\n",
    "\n",
    "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
    "                  see http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "                  plt.get_cmap('jet') or plt.cm.Blues\n",
    "\n",
    "    normalize:    If False, plot the raw numbers\n",
    "                  If True, plot the proportions\n",
    "\n",
    "    Usage\n",
    "    -----\n",
    "    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n",
    "                                                              # sklearn.metrics.confusion_matrix\n",
    "                          normalize    = True,                # show proportions\n",
    "                          target_names = y_labels_vals,       # list of names of the classes\n",
    "                          title        = best_estimator_name) # title of graph\n",
    "\n",
    "    Citiation\n",
    "    ---------\n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    \n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.tight_layout()\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##saving the classification report\n",
    "def pandas_classification_report(y_true, y_pred):\n",
    "    metrics_summary = precision_recall_fscore_support(\n",
    "            y_true=y_true, \n",
    "            y_pred=y_pred)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    \n",
    "    avg = list(precision_recall_fscore_support(\n",
    "            y_true=y_true, \n",
    "            y_pred=y_pred,\n",
    "            average='macro'))\n",
    "    avg.append(accuracy_score(y_true, y_pred, normalize=True))\n",
    "    metrics_sum_index = ['precision', 'recall', 'f1-score', 'support','accuracy']\n",
    "    list_all=list(metrics_summary)\n",
    "    list_all.append(cm.diagonal())\n",
    "    class_report_df = pd.DataFrame(\n",
    "        list_all,\n",
    "        index=metrics_sum_index)\n",
    "\n",
    "    support = class_report_df.loc['support']\n",
    "    total = support.sum() \n",
    "    avg[-2] = total\n",
    "\n",
    "    class_report_df['avg / total'] = avg\n",
    "\n",
    "    return class_report_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....start....cleaning\n"
     ]
    }
   ],
   "source": [
    "from commen_preprocess import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eng_train_dataset = pd.read_csv('../AMI@EVALITA2018/en_training.tsv', sep='\\t')\n",
    "eng_test_dataset = pd.read_csv('../AMI@EVALITA2018/en_testing.tsv', sep='\\t')\n",
    "eng_train_dataset = eng_train_dataset.sample(frac=1).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>misogynous</th>\n",
       "      <th>misogyny_category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>140</td>\n",
       "      <td>This pussy mine girl tell me you like Daddy di...</td>\n",
       "      <td>1</td>\n",
       "      <td>discredit</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2824</td>\n",
       "      <td>When your wingman gets bunned up and leaves yo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1812</td>\n",
       "      <td>@glaiveXD WHERE THE FUCK AM I U STUPID CUNT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>349</td>\n",
       "      <td>When you join a relationship women leave this ...</td>\n",
       "      <td>1</td>\n",
       "      <td>stereotype</td>\n",
       "      <td>passive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>273</td>\n",
       "      <td>Twinkle twinkle little slut, you've got just w...</td>\n",
       "      <td>1</td>\n",
       "      <td>sexual_harassment</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>593</td>\n",
       "      <td>Bitch I know you are not there https://t.co/G4...</td>\n",
       "      <td>1</td>\n",
       "      <td>discredit</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3145</td>\n",
       "      <td>Me flirting- *pulls phone out* 'Look at my dic...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1577</td>\n",
       "      <td>It's not rape if women are considered objects!...</td>\n",
       "      <td>1</td>\n",
       "      <td>dominance</td>\n",
       "      <td>passive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3499</td>\n",
       "      <td>RT MightyBusterBro: MOST HATED WOMAN Hysterica...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2914</td>\n",
       "      <td>I just got a ticket but in my defense I didn't...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3047</td>\n",
       "      <td>Friend- I'm getting married Me- https://t.co/h...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3500</td>\n",
       "      <td>@WithMyPrez4Ever It‚Äôs hysterical! If I were th...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3983</td>\n",
       "      <td>Conte being a little bitch as per. Get sacked ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1000</td>\n",
       "      <td>@aboyseth mermaids are women. Therefore they s...</td>\n",
       "      <td>1</td>\n",
       "      <td>dominance</td>\n",
       "      <td>passive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2753</td>\n",
       "      <td>Her- you usually wear condoms tho, right? Me- ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3498</td>\n",
       "      <td>#nowPlaying Regain Your Poise Hysterical Woman...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>674</td>\n",
       "      <td>@ImCardiB being a empowering woman type a bitc...</td>\n",
       "      <td>1</td>\n",
       "      <td>discredit</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>33</td>\n",
       "      <td>also this girl tried to twerk me away from bar...</td>\n",
       "      <td>1</td>\n",
       "      <td>sexual_harassment</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>621</td>\n",
       "      <td>@AnngelicaaPerez Bitch come out you love to ta...</td>\n",
       "      <td>1</td>\n",
       "      <td>discredit</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1345</td>\n",
       "      <td>Dear Akkorou, Bitch ass nigga cunt on a stick ...</td>\n",
       "      <td>1</td>\n",
       "      <td>discredit</td>\n",
       "      <td>passive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3089</td>\n",
       "      <td>RT @themrsqueenbee: I'm just a materialistic n...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3105</td>\n",
       "      <td>Idk who these things are or why they're popula...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>113</td>\n",
       "      <td>lil is beautiful, gays are cute, i'm very stro...</td>\n",
       "      <td>1</td>\n",
       "      <td>discredit</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3362</td>\n",
       "      <td>Neter Sesen Book 2 Verses 61 -62: Tehuti: 'Do ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2811</td>\n",
       "      <td>People that hate on you that you've done nothi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1682</td>\n",
       "      <td>1 hoe 2 hoe 3 hoe 4, girl you know you're just...</td>\n",
       "      <td>1</td>\n",
       "      <td>discredit</td>\n",
       "      <td>passive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2775</td>\n",
       "      <td>RT @ggwbt: üò¨ #goodgirlwithbadthoughts üíÖüèΩ https...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>833</td>\n",
       "      <td>What's the difference between your wife and yo...</td>\n",
       "      <td>1</td>\n",
       "      <td>discredit</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>494</td>\n",
       "      <td>I'm back in it bitch If the head game is right...</td>\n",
       "      <td>1</td>\n",
       "      <td>sexual_harassment</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2542</td>\n",
       "      <td>When you're trying to figure out if you have e...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3970</th>\n",
       "      <td>1006</td>\n",
       "      <td>@Carflyy she's a woman. She can't help the fac...</td>\n",
       "      <td>1</td>\n",
       "      <td>dominance</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3971</th>\n",
       "      <td>2165</td>\n",
       "      <td>A middle aged woman just shouted 'well done' a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3972</th>\n",
       "      <td>2702</td>\n",
       "      <td>When someone tries to take the last piece of p...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3973</th>\n",
       "      <td>386</td>\n",
       "      <td>@BasicMormon So do we! Check out our account f...</td>\n",
       "      <td>1</td>\n",
       "      <td>dominance</td>\n",
       "      <td>passive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3974</th>\n",
       "      <td>1849</td>\n",
       "      <td>Sometimes you gotta beat ya dick like it stole...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3975</th>\n",
       "      <td>3588</td>\n",
       "      <td>Waking up Sunday morning hungover as fuck like...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3976</th>\n",
       "      <td>2869</td>\n",
       "      <td>It must suck to not be me</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3977</th>\n",
       "      <td>1409</td>\n",
       "      <td>Y‚Äôall expect women to settle for trash treatme...</td>\n",
       "      <td>1</td>\n",
       "      <td>discredit</td>\n",
       "      <td>passive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3978</th>\n",
       "      <td>1564</td>\n",
       "      <td>@DrPhil you mean she still has morals after wh...</td>\n",
       "      <td>1</td>\n",
       "      <td>sexual_harassment</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3979</th>\n",
       "      <td>1192</td>\n",
       "      <td>@SantinaDiMaggio happy birthday ya lil freak! ...</td>\n",
       "      <td>1</td>\n",
       "      <td>sexual_harassment</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3980</th>\n",
       "      <td>830</td>\n",
       "      <td>What does a woman and a tampon have in common?...</td>\n",
       "      <td>1</td>\n",
       "      <td>discredit</td>\n",
       "      <td>passive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3981</th>\n",
       "      <td>590</td>\n",
       "      <td>What a stupid cunt https://t.co/Wv1rVaId2D</td>\n",
       "      <td>1</td>\n",
       "      <td>discredit</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3982</th>\n",
       "      <td>211</td>\n",
       "      <td>@AmericansRDumb1 dont u have anything better t...</td>\n",
       "      <td>1</td>\n",
       "      <td>discredit</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3983</th>\n",
       "      <td>1838</td>\n",
       "      <td>Ahhh my cousin's fetus doesn't have a dick and...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3984</th>\n",
       "      <td>855</td>\n",
       "      <td>When you finally get the bitch to leave https:...</td>\n",
       "      <td>1</td>\n",
       "      <td>discredit</td>\n",
       "      <td>passive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3985</th>\n",
       "      <td>2123</td>\n",
       "      <td>you made yourself a bed at the bottom of the b...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3986</th>\n",
       "      <td>2594</td>\n",
       "      <td>Flirting in 2016 https://t.co/6K9rVnYZjA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3987</th>\n",
       "      <td>4038</td>\n",
       "      <td>@jojolang9 @KurtSchlichter Congratulations, Jo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3988</th>\n",
       "      <td>484</td>\n",
       "      <td>What happens when you drug, rape and sodomize ...</td>\n",
       "      <td>1</td>\n",
       "      <td>sexual_harassment</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3989</th>\n",
       "      <td>3175</td>\n",
       "      <td>If you can't spell 'masturbate' right, we can'...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3990</th>\n",
       "      <td>2280</td>\n",
       "      <td>@GrimoireOfKenji I'd like to think you just bl...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3991</th>\n",
       "      <td>3619</td>\n",
       "      <td>If you actually believe a woman 'asks' to be r...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3992</th>\n",
       "      <td>1278</td>\n",
       "      <td>I FUCKING TOLD YOU SKANK WHORE SLUTS LISTEN TO...</td>\n",
       "      <td>1</td>\n",
       "      <td>dominance</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3993</th>\n",
       "      <td>1056</td>\n",
       "      <td>Don't get offended ladies, men are always right</td>\n",
       "      <td>1</td>\n",
       "      <td>dominance</td>\n",
       "      <td>passive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3994</th>\n",
       "      <td>3849</td>\n",
       "      <td>Wonder how insecure you have to be to tweet #N...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>136</td>\n",
       "      <td>@ThePatriot143 Dirty smelly cunt slut whores. ...</td>\n",
       "      <td>1</td>\n",
       "      <td>discredit</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>3225</td>\n",
       "      <td>@Marinosepass Chuck Bass kept waking you up be...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>3164</td>\n",
       "      <td>A healthy amount of sperm https://t.co/Y1aPgCuink</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>76</td>\n",
       "      <td>...............................'I get to rape ...</td>\n",
       "      <td>1</td>\n",
       "      <td>sexual_harassment</td>\n",
       "      <td>passive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>3353</td>\n",
       "      <td>@nyvic26 And 4. I was calling you the sexist. ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text  misogynous  \\\n",
       "0      140  This pussy mine girl tell me you like Daddy di...           1   \n",
       "1     2824  When your wingman gets bunned up and leaves yo...           0   \n",
       "2     1812        @glaiveXD WHERE THE FUCK AM I U STUPID CUNT           0   \n",
       "3      349  When you join a relationship women leave this ...           1   \n",
       "4      273  Twinkle twinkle little slut, you've got just w...           1   \n",
       "5      593  Bitch I know you are not there https://t.co/G4...           1   \n",
       "6     3145  Me flirting- *pulls phone out* 'Look at my dic...           0   \n",
       "7     1577  It's not rape if women are considered objects!...           1   \n",
       "8     3499  RT MightyBusterBro: MOST HATED WOMAN Hysterica...           0   \n",
       "9     2914  I just got a ticket but in my defense I didn't...           0   \n",
       "10    3047  Friend- I'm getting married Me- https://t.co/h...           0   \n",
       "11    3500  @WithMyPrez4Ever It‚Äôs hysterical! If I were th...           0   \n",
       "12    3983  Conte being a little bitch as per. Get sacked ...           0   \n",
       "13    1000  @aboyseth mermaids are women. Therefore they s...           1   \n",
       "14    2753  Her- you usually wear condoms tho, right? Me- ...           0   \n",
       "15    3498  #nowPlaying Regain Your Poise Hysterical Woman...           0   \n",
       "16     674  @ImCardiB being a empowering woman type a bitc...           1   \n",
       "17      33  also this girl tried to twerk me away from bar...           1   \n",
       "18     621  @AnngelicaaPerez Bitch come out you love to ta...           1   \n",
       "19    1345  Dear Akkorou, Bitch ass nigga cunt on a stick ...           1   \n",
       "20    3089  RT @themrsqueenbee: I'm just a materialistic n...           0   \n",
       "21    3105  Idk who these things are or why they're popula...           0   \n",
       "22     113  lil is beautiful, gays are cute, i'm very stro...           1   \n",
       "23    3362  Neter Sesen Book 2 Verses 61 -62: Tehuti: 'Do ...           0   \n",
       "24    2811  People that hate on you that you've done nothi...           0   \n",
       "25    1682  1 hoe 2 hoe 3 hoe 4, girl you know you're just...           1   \n",
       "26    2775  RT @ggwbt: üò¨ #goodgirlwithbadthoughts üíÖüèΩ https...           0   \n",
       "27     833  What's the difference between your wife and yo...           1   \n",
       "28     494  I'm back in it bitch If the head game is right...           1   \n",
       "29    2542  When you're trying to figure out if you have e...           0   \n",
       "...    ...                                                ...         ...   \n",
       "3970  1006  @Carflyy she's a woman. She can't help the fac...           1   \n",
       "3971  2165  A middle aged woman just shouted 'well done' a...           0   \n",
       "3972  2702  When someone tries to take the last piece of p...           0   \n",
       "3973   386  @BasicMormon So do we! Check out our account f...           1   \n",
       "3974  1849  Sometimes you gotta beat ya dick like it stole...           0   \n",
       "3975  3588  Waking up Sunday morning hungover as fuck like...           0   \n",
       "3976  2869                          It must suck to not be me           0   \n",
       "3977  1409  Y‚Äôall expect women to settle for trash treatme...           1   \n",
       "3978  1564  @DrPhil you mean she still has morals after wh...           1   \n",
       "3979  1192  @SantinaDiMaggio happy birthday ya lil freak! ...           1   \n",
       "3980   830  What does a woman and a tampon have in common?...           1   \n",
       "3981   590         What a stupid cunt https://t.co/Wv1rVaId2D           1   \n",
       "3982   211  @AmericansRDumb1 dont u have anything better t...           1   \n",
       "3983  1838  Ahhh my cousin's fetus doesn't have a dick and...           0   \n",
       "3984   855  When you finally get the bitch to leave https:...           1   \n",
       "3985  2123  you made yourself a bed at the bottom of the b...           0   \n",
       "3986  2594           Flirting in 2016 https://t.co/6K9rVnYZjA           0   \n",
       "3987  4038  @jojolang9 @KurtSchlichter Congratulations, Jo...           0   \n",
       "3988   484  What happens when you drug, rape and sodomize ...           1   \n",
       "3989  3175  If you can't spell 'masturbate' right, we can'...           0   \n",
       "3990  2280  @GrimoireOfKenji I'd like to think you just bl...           0   \n",
       "3991  3619  If you actually believe a woman 'asks' to be r...           0   \n",
       "3992  1278  I FUCKING TOLD YOU SKANK WHORE SLUTS LISTEN TO...           1   \n",
       "3993  1056    Don't get offended ladies, men are always right           1   \n",
       "3994  3849  Wonder how insecure you have to be to tweet #N...           0   \n",
       "3995   136  @ThePatriot143 Dirty smelly cunt slut whores. ...           1   \n",
       "3996  3225  @Marinosepass Chuck Bass kept waking you up be...           0   \n",
       "3997  3164  A healthy amount of sperm https://t.co/Y1aPgCuink           0   \n",
       "3998    76  ...............................'I get to rape ...           1   \n",
       "3999  3353  @nyvic26 And 4. I was calling you the sexist. ...           0   \n",
       "\n",
       "      misogyny_category   target  \n",
       "0             discredit   active  \n",
       "1                     0        0  \n",
       "2                     0        0  \n",
       "3            stereotype  passive  \n",
       "4     sexual_harassment   active  \n",
       "5             discredit   active  \n",
       "6                     0        0  \n",
       "7             dominance  passive  \n",
       "8                     0        0  \n",
       "9                     0        0  \n",
       "10                    0        0  \n",
       "11                    0        0  \n",
       "12                    0        0  \n",
       "13            dominance  passive  \n",
       "14                    0        0  \n",
       "15                    0        0  \n",
       "16            discredit   active  \n",
       "17    sexual_harassment   active  \n",
       "18            discredit   active  \n",
       "19            discredit  passive  \n",
       "20                    0        0  \n",
       "21                    0        0  \n",
       "22            discredit   active  \n",
       "23                    0        0  \n",
       "24                    0        0  \n",
       "25            discredit  passive  \n",
       "26                    0        0  \n",
       "27            discredit   active  \n",
       "28    sexual_harassment   active  \n",
       "29                    0        0  \n",
       "...                 ...      ...  \n",
       "3970          dominance   active  \n",
       "3971                  0        0  \n",
       "3972                  0        0  \n",
       "3973          dominance  passive  \n",
       "3974                  0        0  \n",
       "3975                  0        0  \n",
       "3976                  0        0  \n",
       "3977          discredit  passive  \n",
       "3978  sexual_harassment   active  \n",
       "3979  sexual_harassment   active  \n",
       "3980          discredit  passive  \n",
       "3981          discredit   active  \n",
       "3982          discredit   active  \n",
       "3983                  0        0  \n",
       "3984          discredit  passive  \n",
       "3985                  0        0  \n",
       "3986                  0        0  \n",
       "3987                  0        0  \n",
       "3988  sexual_harassment   active  \n",
       "3989                  0        0  \n",
       "3990                  0        0  \n",
       "3991                  0        0  \n",
       "3992          dominance   active  \n",
       "3993          dominance  passive  \n",
       "3994                  0        0  \n",
       "3995          discredit   active  \n",
       "3996                  0        0  \n",
       "3997                  0        0  \n",
       "3998  sexual_harassment  passive  \n",
       "3999                  0        0  \n",
       "\n",
       "[4000 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                    2215\n",
       "discredit            1014\n",
       "sexual_harassment     352\n",
       "stereotype            179\n",
       "dominance             148\n",
       "derailing              92\n",
       "Name: misogyny_category, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_train_dataset['misogyny_category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Loading Glove Model\n",
      "count10000\n",
      "count20000\n",
      "count30000\n",
      "count40000\n",
      "count50000\n",
      "count60000\n",
      "count70000\n",
      "count80000\n",
      "count90000\n",
      "count100000\n",
      "count110000\n",
      "count120000\n",
      "count130000\n",
      "count140000\n",
      "count150000\n",
      "count160000\n",
      "count170000\n",
      "count180000\n",
      "count190000\n",
      "count200000\n",
      "count210000\n",
      "count220000\n",
      "count230000\n",
      "count240000\n",
      "count250000\n",
      "count260000\n",
      "count270000\n",
      "count280000\n",
      "count290000\n",
      "count300000\n",
      "count310000\n",
      "count320000\n",
      "count330000\n",
      "count340000\n",
      "count350000\n",
      "count360000\n",
      "count370000\n",
      "count380000\n",
      "count390000\n",
      "count400000\n",
      "count410000\n",
      "count420000\n",
      "count430000\n",
      "count440000\n",
      "count450000\n",
      "count460000\n",
      "count470000\n",
      "count480000\n",
      "count490000\n",
      "count500000\n",
      "count510000\n",
      "count520000\n",
      "count530000\n",
      "count540000\n",
      "count550000\n",
      "count560000\n",
      "count570000\n",
      "count580000\n",
      "count590000\n",
      "count600000\n",
      "count610000\n",
      "count620000\n",
      "count630000\n",
      "count640000\n",
      "count650000\n",
      "count660000\n",
      "count670000\n",
      "count680000\n",
      "count690000\n",
      "count700000\n",
      "count710000\n",
      "count720000\n",
      "count730000\n",
      "count740000\n",
      "count750000\n",
      "count760000\n",
      "count770000\n",
      "count780000\n",
      "count790000\n",
      "count800000\n",
      "count810000\n",
      "count820000\n",
      "count830000\n",
      "count840000\n",
      "count850000\n",
      "count860000\n",
      "count870000\n",
      "count880000\n",
      "count890000\n",
      "count900000\n",
      "count910000\n",
      "count920000\n",
      "count930000\n",
      "count940000\n",
      "count950000\n",
      "count960000\n",
      "count970000\n",
      "count980000\n",
      "count990000\n",
      "count1000000\n",
      "count1010000\n",
      "count1020000\n",
      "count1030000\n",
      "count1040000\n",
      "count1050000\n",
      "count1060000\n",
      "count1070000\n",
      "count1080000\n",
      "count1090000\n",
      "count1100000\n",
      "count1110000\n",
      "count1120000\n",
      "count1130000\n",
      "count1140000\n",
      "count1150000\n",
      "count1160000\n",
      "count1170000\n",
      "count1180000\n",
      "count1190000\n",
      "Done. 1193515  words loaded!\n"
     ]
    }
   ],
   "source": [
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "import os\n",
    "GLOVE_MODEL_FILE = \"../../LEAM-master/glove.twitter.27B/glove.twitter.27B.200d.txt\"\n",
    "# GLOVE_MODEL_FILE=\"../../../glove.840B.300d.txt\"\n",
    "print(os.path.isfile(GLOVE_MODEL_FILE))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "def loadGloveModel(gloveFile):\n",
    "    print(\"Loading Glove Model\")\n",
    "    f = open(gloveFile,'r', encoding='utf8')\n",
    "    model = {}\n",
    "    i=0\n",
    "    for line in f:\n",
    "        i=i+1\n",
    "        splitLine = line.split(' ')\n",
    "        word = splitLine[0]\n",
    "        embedding = np.asarray(splitLine[1:], dtype='float32')\n",
    "        model[word] = embedding\n",
    "        if(i%10000==0):\n",
    "            print(\"count\"+str(i))\n",
    "    print(\"Done.\",len(model),\" words loaded!\")\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "EMBEDDING_DIM = 200\n",
    "\n",
    "\n",
    "# glove_file = GLOVE_MODEL_FILE\n",
    "# tmp_file = get_tmpfile(\"test_crawl_300.txt\")\n",
    "\n",
    "# # call glove2word2vec script\n",
    "# # default way (through CLI): python -m gensim.scripts.glove2word2vec --input <glove_file> --output <w2v_file>\n",
    "# from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "# glove2word2vec(glove_file, tmp_file)\n",
    "\n",
    "\n",
    "# # In[29]:\n",
    "\n",
    "\n",
    "# word2vec_model = KeyedVectors.load_word2vec_format(tmp_file)\n",
    "word2vec_model = loadGloveModel(GLOVE_MODEL_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### stopwords and punctuations are not removed but text is cleaned and stemmed\n",
    "def glove_tokenize_norem(text):\n",
    "    #text = tokenizer(text)\n",
    "    text=clean(text, remove_stopwords=False, remove_punctuations=False)\n",
    "    words = text.split()\n",
    "    words =[ps.stem(word) for word in words]\n",
    "    return words\n",
    "\n",
    "####stopwords and punctuations are removed along with that text is cleaned ans stemmed\n",
    "def glove_tokenize(text):\n",
    "    #text = tokenizer(text)\n",
    "    text=clean(text, remove_stopwords=False, remove_punctuations=False)\n",
    "    text = ''.join([c for c in text if c not in punctuation])\n",
    "    words = text.split()\n",
    "    words = [word for word in words if word not in STOPWORDS]\n",
    "    words =[ps.stem(word) for word in words]\n",
    "    return words\n",
    "def glove_tokenize_embed(text):\n",
    "    #text = tokenizer(text)\n",
    "    text=clean(text, remove_stopwords=False, remove_punctuations=False)\n",
    "    text = ''.join([c for c in text if c not in punctuation])\n",
    "    words = text.split()\n",
    "    words = [word for word in words if word not in STOPWORDS]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_class_label(input_text):\n",
    "    if input_text==1:\n",
    "        return 'misogyny'\n",
    "    elif input_text==0:\n",
    "        return 'non-misogyny'\n",
    "    else:\n",
    "        print('Wrong Input', input_text)\n",
    "        sys.exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Loading Completed...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/binny/anaconda3/envs/punyajoy-nogpu/lib/python3.5/site-packages/ipykernel/__main__.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# pd_train = pd.DataFrame(columns=['id','misogynous','text'])\n",
    "eng_train_dataset[\"text\"].replace('', np.nan, inplace=True)\n",
    "eng_train_dataset.dropna(subset=['text'], inplace=True)\n",
    "\n",
    "pd_train_binary = eng_train_dataset[['id','misogynous','text','misogyny_category','target']]\n",
    "pd_train_category = eng_train_dataset[['id','misogynous','text','misogyny_category']]\n",
    "pd_train_target = eng_train_dataset[['id','misogynous','text','target']]\n",
    "pd_test = eng_test_dataset[['id','text']]\n",
    "\n",
    "pd_train_category = pd_train_category.loc[pd_train_category['misogynous'] == 1]\n",
    "pd_train_target = pd_train_target.loc[pd_train_target['misogynous'] == 1]\n",
    "pd_train_target.drop(['misogynous'], axis=1)                                      \n",
    "pd_train_category.drop(['misogynous'], axis=1)                                      \n",
    "\n",
    "# pd_train['class'] =pd_train.apply(lambda row: convert_class_label(row['misogynous']), axis=1)\n",
    "\n",
    "pd_train_binary['class'] = pd_train_binary['misogynous']\n",
    "pd_train_category['class'] = pd_train_category['misogyny_category']\n",
    "pd_train_target['class'] = pd_train_target['target']\n",
    "\n",
    "# for count, each in enumerate(train_data):\n",
    "#     try:\n",
    "#         pd_train.loc[count]  = [each['id'], convert_class_label(each['CounterSpeech']), each['Community'],each['Category'],each['commentText']]\n",
    "#     except:\n",
    "#         pass\n",
    "print('Training Data Loading Completed...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data(pd_train):\n",
    "    comments=pd_train['text'].values\n",
    "    labels=pd_train['class'].values\n",
    "    list_comment=[]\n",
    "    for comment,label in zip(comments,labels):\n",
    "        temp={}\n",
    "        temp['text']=comment\n",
    "        temp['label']=label\n",
    "        list_comment.append(temp)\n",
    "    return list_comment \n",
    "\n",
    "def get_data_test(pd_test):\n",
    "    comments=pd_test['text'].values\n",
    "    list_comment=[]\n",
    "    for comment in comments:\n",
    "        temp={}\n",
    "        temp['text']=comment\n",
    "        list_comment.append(temp)\n",
    "    return list_comment \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/binny/anaconda3/envs/punyajoy-nogpu/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using /tmp/tfhub_modules to cache modules.\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_0:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Embeddings_en/sharded_0\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_1:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Embeddings_en/sharded_1\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_10:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Embeddings_en/sharded_10\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_11:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Embeddings_en/sharded_11\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_12:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Embeddings_en/sharded_12\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_13:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Embeddings_en/sharded_13\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_14:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Embeddings_en/sharded_14\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_15:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Embeddings_en/sharded_15\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_16:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Embeddings_en/sharded_16\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_2:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Embeddings_en/sharded_2\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_3:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Embeddings_en/sharded_3\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_4:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Embeddings_en/sharded_4\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_5:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Embeddings_en/sharded_5\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_6:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Embeddings_en/sharded_6\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_7:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Embeddings_en/sharded_7\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_8:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Embeddings_en/sharded_8\n",
      "INFO:tensorflow:Initialize variable module/Embeddings_en/sharded_9:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Embeddings_en/sharded_9\n",
      "INFO:tensorflow:Initialize variable module/Encoder_en/DNN/ResidualHidden_0/weights:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Encoder_en/DNN/ResidualHidden_0/weights\n",
      "INFO:tensorflow:Initialize variable module/Encoder_en/DNN/ResidualHidden_1/weights:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Encoder_en/DNN/ResidualHidden_1/weights\n",
      "INFO:tensorflow:Initialize variable module/Encoder_en/DNN/ResidualHidden_2/weights:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Encoder_en/DNN/ResidualHidden_2/weights\n",
      "INFO:tensorflow:Initialize variable module/Encoder_en/DNN/ResidualHidden_3/projection:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Encoder_en/DNN/ResidualHidden_3/projection\n",
      "INFO:tensorflow:Initialize variable module/Encoder_en/DNN/ResidualHidden_3/weights:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with Encoder_en/DNN/ResidualHidden_3/weights\n",
      "INFO:tensorflow:Initialize variable module/SHARED_RANK_ANSWER/response_encoder_0/tanh_layer_0/bias:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with SHARED_RANK_ANSWER/response_encoder_0/tanh_layer_0/bias\n",
      "INFO:tensorflow:Initialize variable module/SHARED_RANK_ANSWER/response_encoder_0/tanh_layer_0/weights:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with SHARED_RANK_ANSWER/response_encoder_0/tanh_layer_0/weights\n",
      "INFO:tensorflow:Initialize variable module/SHARED_RANK_ANSWER/response_encoder_0/tanh_layer_1/bias:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with SHARED_RANK_ANSWER/response_encoder_0/tanh_layer_1/bias\n",
      "INFO:tensorflow:Initialize variable module/SHARED_RANK_ANSWER/response_encoder_0/tanh_layer_1/weights:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with SHARED_RANK_ANSWER/response_encoder_0/tanh_layer_1/weights\n",
      "INFO:tensorflow:Initialize variable module/SHARED_RANK_ANSWER/response_encoder_0/tanh_layer_2/bias:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with SHARED_RANK_ANSWER/response_encoder_0/tanh_layer_2/bias\n",
      "INFO:tensorflow:Initialize variable module/SHARED_RANK_ANSWER/response_encoder_0/tanh_layer_2/weights:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with SHARED_RANK_ANSWER/response_encoder_0/tanh_layer_2/weights\n",
      "INFO:tensorflow:Initialize variable module/SNLI/Classifier/LinearLayer/bias:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with SNLI/Classifier/LinearLayer/bias\n",
      "INFO:tensorflow:Initialize variable module/SNLI/Classifier/LinearLayer/weights:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with SNLI/Classifier/LinearLayer/weights\n",
      "INFO:tensorflow:Initialize variable module/SNLI/Classifier/tanh_layer_0/bias:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with SNLI/Classifier/tanh_layer_0/bias\n",
      "INFO:tensorflow:Initialize variable module/SNLI/Classifier/tanh_layer_0/weights:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with SNLI/Classifier/tanh_layer_0/weights\n",
      "INFO:tensorflow:Initialize variable module/global_step:0 from checkpoint b'/tmp/tfhub_modules/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/variables/variables' with global_step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/2\" #@param [\"https://tfhub.dev/google/universal-sentence-encoder/2\", \"https://tfhub.dev/google/universal-sentence-encoder-large/3\"]\n",
    "embed = hub.Module(module_url)\n",
    "config = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=12,\n",
    "                       allow_soft_placement=True, device_count = {'CPU': 12})\n",
    "\n",
    "def get_embeddings(messages):\n",
    "      \n",
    "    with tf.Session(config=config) as session:\n",
    "            session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "            message_emb = session.run(embed(messages))\n",
    "            \n",
    "    print(\"ending\")\n",
    "    return np.array(message_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "\n",
    "TOKENIZER = glove_tokenize\n",
    "#google encoding used where text is cleaned  \n",
    "def gen_data_google(data):\n",
    "    comments = get_data(data)\n",
    "    X, y = [], []\n",
    "    for comment in comments:\n",
    "        y.append(comment['label'])\n",
    "        #X.append(tokenizer(comment['text']))\n",
    "        X.append(clean(comment['text'], remove_stopwords=True, remove_punctuations=True))\n",
    "    #TFIDF_feature = 'bpe_text'\n",
    "\n",
    "    #Word Level Features\n",
    "    X =get_embeddings(X)\n",
    "    # print y\n",
    "    #y = MultiLabelBinarizer(classes = (1,2,3,4,5,6,7,8,9,10)).fit_transform(y)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "#google encoding used where text is not cleaned \n",
    "def gen_data_google2(data):\n",
    "    comments = get_data(data)\n",
    "    X, y = [],[]\n",
    "    for comment in comments:\n",
    "        y.append(comment['label'])\n",
    "        X.append(clean(comment['text'], remove_stopwords=False, remove_punctuations=False))\n",
    "    #Word Level Features\n",
    "    X =get_embeddings(X)\n",
    "    #y = MultiLabelBinarizer(classes = (1,2,3,4,5,6,7,8,9,10)).fit_transform(y)\n",
    "    return X,y\n",
    "\n",
    "### tfidf feature generation was used here where stopwords and punctuations are removed \n",
    "def gen_data_new_tfidf(data):\n",
    "    comments = get_data(data)\n",
    "    comments_test=get_data_test(pd_test)\n",
    "    X, y = [], []\n",
    "    for comment in comments:\n",
    "        y.append(comment['label'])\n",
    "        X.append(comment['text'])\n",
    "\n",
    "    X1=[]\n",
    "    for comment in comments_test:\n",
    "        X1.append(comment['text'])\n",
    "\n",
    "\n",
    "    #Word Level Features\n",
    "    word_vectorizer = TfidfVectorizer(sublinear_tf=True, ngram_range=(1,3),\n",
    "                min_df=1, \n",
    "                strip_accents='unicode',\n",
    "                #smooth_idf=1,\n",
    "                analyzer='word', \n",
    "                stop_words='english',\n",
    "                tokenizer=TOKENIZER,             \n",
    "                max_features=5000)\n",
    "    \n",
    "    \n",
    "    #charlevel features new\n",
    "    char_vectorizer = TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    strip_accents='unicode',\n",
    "    analyzer='char',\n",
    "    #stop_words='english',\n",
    "    ngram_range=(2, 6),\n",
    "    max_features=10000)\n",
    "    word_vectorizer.fit(X+X1)\n",
    "    char_vectorizer.fit(X+X1)\n",
    "    \n",
    "    with open('tfidf_word_vectorizer.pk', 'wb') as fout:\n",
    "         pickle.dump(word_vectorizer,fout)\n",
    "\n",
    "    with open('tfidf_char_vectorizer.pk', 'wb') as fout:\n",
    "        pickle.dump(char_vectorizer,fout)\n",
    "    \n",
    "    test_word_features = word_vectorizer.transform(X)\n",
    "    test_char_features = char_vectorizer.transform(X)\n",
    "    X = list(hstack([test_char_features, test_word_features]).toarray())\n",
    "    #y = MultiLabelBinarizer(classes = (1,2,3,4,5,6,7,8,9,10)).fit_transform(y)\n",
    "    return X, y\n",
    "\n",
    "### tfidf feature generation was used here where stopwords and punctuations are not removed \n",
    "def gen_data_new_tfidf2(data):\n",
    "    comments = get_data(data)\n",
    "    X, y = [], []\n",
    "    for comment in comments:\n",
    "        y.append(comment['label'])\n",
    "        X.append(comment['text'])\n",
    "\n",
    "\n",
    "    #Word Level Features\n",
    "    word_vectorizer = TfidfVectorizer(sublinear_tf=True, ngram_range=(1,3),\n",
    "                min_df=1, \n",
    "                strip_accents='unicode',\n",
    "                #smooth_idf=1,\n",
    "                analyzer='word', \n",
    "                #stop_words='english',\n",
    "                tokenizer=glove_tokenize_norem,             \n",
    "                max_features=5000)\n",
    "    \n",
    "    \n",
    "    #charlevel features new\n",
    "    char_vectorizer = TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    strip_accents='unicode',\n",
    "    analyzer='char',\n",
    "    #stop_words='english',\n",
    "    ngram_range=(2, 6),\n",
    "    max_features=10000)\n",
    "    \n",
    "    word_vectorizer.fit(X)\n",
    "    char_vectorizer.fit(X)\n",
    "    \n",
    "    with open('tfidf_word_vectorize_noclean.pk', 'wb') as fout:\n",
    "         pickle.dump(word_vectorizer,fout)\n",
    "\n",
    "    with open('tfidf_char_vectorizer_noclean.pk', 'wb') as fout:\n",
    "         pickle.dump(char_vectorizer,fout)\n",
    "        \n",
    "    test_word_features = word_vectorizer.transform(X)\n",
    "    test_char_features = char_vectorizer.transform(X)\n",
    "    X = list(hstack([test_char_features, test_word_features]).toarray())\n",
    "    #y = MultiLabelBinarizer(classes = (1,2,3,4,5,6,7,8,9,10)).fit_transform(y)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "## combination of not cleaned google encodings and tfidf features where stopwords and punctuations are not removed \n",
    "def combine_tf_google_rem(data):\n",
    "    X,_=gen_data_google(data)\n",
    "    X1,y=gen_data_new_tfidf(data)\n",
    "#     X1,y=gen_data_old_tfidf()\n",
    "    X=np.concatenate((np.array(X), np.array(X1)), axis=1)\n",
    "    return X,y\n",
    "\n",
    "## combination of cleaned google encodings and tfidf features where stopwords and punctuations are ssremoved \n",
    "def combine_tf_google_norem(data):\n",
    "    X,_=gen_data_google2(data)\n",
    "    X1,y=gen_data_new_tfidf2(data)\n",
    "    X=np.concatenate((np.array(X), np.array(X1)), axis=1)\n",
    "    return X,y\n",
    "\n",
    "def combine_tf_rem_google_norem(data):\n",
    "    X,_=gen_data_google2(data)\n",
    "    X1,y=gen_data_new_tfidf(data)\n",
    "    X=np.concatenate((np.array(X), np.array(X1)), axis=1)\n",
    "    return X,y\n",
    "\n",
    "def combine_tf_norem_google_rem(data):\n",
    "    X,_=gen_data_google(data)\n",
    "    X1,y=gen_data_new_tfidf2(data)\n",
    "    X=np.concatenate((np.array(X), np.array(X1)), axis=1)\n",
    "    return X,y\n",
    "\n",
    "def gen_data_embed(data):\n",
    "    comments = get_data(data)\n",
    "    X, y = [], []\n",
    "    for comment in comments:\n",
    "        words = glove_tokenize(comment['text'].lower())\n",
    "        emb = np.zeros(EMBEDDING_DIM)\n",
    "        for word in words:\n",
    "            try:\n",
    "                emb += word2vec_model[word]\n",
    "            except:\n",
    "                pass\n",
    "        if len(words)!=0:\n",
    "            emb /= len(words)\n",
    "        X.append(emb)\n",
    "        y.append(comment['label'])\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def combine_tf_rem_google_norem_embed(data):\n",
    "    X,_=gen_data_google2(data)\n",
    "    X1,y=gen_data_new_tfidf(data)\n",
    "    X2,_=gen_data_embed(data)\n",
    "    X=np.concatenate((np.array(X), np.array(X1),np.array(X2)), axis=1)\n",
    "    return X,y\n",
    "\n",
    "\n",
    "\n",
    "###old tfidf\n",
    "\n",
    "def gen_data_old_tfidf(data):\n",
    "    comments = get_data(data)\n",
    "    X, y = [], []\n",
    "    for comment in comments:\n",
    "        y.append(comment['label'])\n",
    "        X.append(comment['text'])\n",
    "    with open('../tfidf_word_vectorizer.pk', 'rb') as fin:\n",
    "        word_vectorizer = pickle.load(fin)\n",
    "\n",
    "    with open('../tfidf_char_vectorizer.pk', 'rb') as fin:\n",
    "        char_vectorizer = pickle.load(fin)\n",
    "\n",
    "\n",
    "    \n",
    "    word_vectorizer.fit(X)\n",
    "    char_vectorizer.fit(X)\n",
    "    \n",
    "    test_word_features = word_vectorizer.transform(X)\n",
    "    test_char_features = char_vectorizer.transform(X)\n",
    "    X = list(hstack([test_char_features, test_word_features]).toarray())\n",
    "    #y = MultiLabelBinarizer(classes = (1,2,3,4,5,6,7,8,9,10)).fit_transform(y)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def select_comments_whose_embedding_exists(flag):\n",
    "    # selects the comments as in mean_glove_embedding method\n",
    "    # Processing\n",
    "    comments = get_data(flag)\n",
    "    X, Y = [], []\n",
    "    comment_return = []\n",
    "    for tweet in comments:\n",
    "        #print(tweet)\n",
    "        _emb = 0\n",
    "        words = TOKENIZER(tweet['text'].lower())\n",
    "        for w in words:\n",
    "            #print(w)\n",
    "            if w in word2vec_model and w is not None:  # Check if embeeding there in GLove model\n",
    "                _emb+=1\n",
    "        if _emb:   # Not a blank tweet\n",
    "            comment_return.append(tweet)\n",
    "    print('Comments selected:', len(comment_return))\n",
    "    return comment_return\n",
    "\n",
    "def gen_data():\n",
    "    comments = select_comments_whose_embedding_exists(0)\n",
    "    X, y = [], []\n",
    "    for comment in comments:\n",
    "        words = glove_tokenize(comment['text'].lower())\n",
    "        emb = numpy.zeros(EMBEDDING_DIM)\n",
    "        for word in words:\n",
    "            try:\n",
    "                emb += word2vec_model[word]\n",
    "            except:\n",
    "                pass\n",
    "        emb /= len(words)\n",
    "        X.append(emb)\n",
    "        y.append(comment['label'])\n",
    "\n",
    "    # print y\n",
    "    y = MultiLabelBinarizer(classes = (1,2,3,4,5,6,7,8,9,10)).fit_transform(y)\n",
    "    print\n",
    "    return X, y\n",
    "\n",
    "## combination of not cleaned google encodings and tfidf features where stopwords and punctuations are not removed \n",
    "def combine_tf_google_glove_rem():\n",
    "    X,_=gen_data_google()\n",
    "    X1,y=gen_data_new_tfidf()\n",
    "#     X1,y=gen_data_old_tfidf()\n",
    "    X=np.concatenate((np.array(X), np.array(X1)), axis=1)\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import ADASYN\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "def get_model(m_type=None):\n",
    "    if not m_type:\n",
    "        print(\"ERROR: Please specify a model type!\")\n",
    "        return None\n",
    "    if m_type == 'decision_tree_classifier':\n",
    "        logreg = tree.DecisionTreeClassifier(class_weight='balanced')\n",
    "    elif m_type == 'gaussian':\n",
    "        logreg = GaussianNB()\n",
    "    elif m_type == 'logistic_regression':\n",
    "        logreg = LogisticRegression(class_weight='balanced',n_jobs=10, random_state=42)\n",
    "    elif m_type == 'MLPClassifier':\n",
    "#         logreg = neural_network.MLPClassifier((500))\n",
    "        logreg = neural_network.MLPClassifier((500),random_state=42,early_stopping=False)\n",
    "    elif m_type == 'KNeighborsClassifier':\n",
    "#         logreg = neighbors.KNeighborsClassifier(n_neighbors = 10)\n",
    "        logreg = neighbors.KNeighborsClassifier()\n",
    "    elif m_type == 'ExtraTreeClassifier':\n",
    "        logreg = tree.ExtraTreeClassifier()\n",
    "    elif m_type == 'ExtraTreeClassifier_2':\n",
    "        logreg = ensemble.ExtraTreesClassifier()\n",
    "    elif m_type == 'RandomForestClassifier':\n",
    "        logreg = ensemble.RandomForestClassifier(n_estimators=100, class_weight='balanced', n_jobs=12, max_depth=3)\n",
    "    elif m_type == 'SVC':\n",
    "        logreg = LinearSVC(class_weight='balanced');\n",
    "    elif m_type == 'Catboost':\n",
    "        logreg = CatBoostClassifier(use_best_model=False,iterations=1000, random_state=42, loss_function='MultiClass',class_weights=[1,3,9,9,9])\n",
    "#         logreg = CatBoostClassifier(scale_pos_weight=0.8, random_seed=42,);\n",
    "    elif m_type == 'XGB_classifier':\n",
    "#         logreg=XGBClassifier(silent=False,eta=0.1,objective='binary:logistic',max_depth=5,min_child_weight=0,gamma=0.2,subsample=0.8, colsample_bytree = 0.8,scale_pos_weight=1,n_estimators=500,reg_lambda=3,nthread=12)\n",
    "        logreg=XGBClassifier(silent=False,objective='binary:logistic',scale_pos_weight=0.8,reg_lambda=3,nthread=12, random_state=42)\n",
    "    elif m_type == 'binny_test':\n",
    "        clf1 = ensemble.RandomForestClassifier(n_estimators=100, class_weight='balanced', n_jobs=12, max_depth=6,max_features='auto')\n",
    "        clf2 = tree.DecisionTreeClassifier(random_state=42, class_weight='balanced',max_depth=6)\n",
    "        clf3 = LogisticRegression(class_weight='balanced',penalty=\"l2\",C=0.1, dual=True, random_state=42, n_jobs=3)\n",
    "        clf4 = XGBClassifier(silent=False,objective='binary:logistic',scale_pos_weight=0.8,reg_lambda=3,nthread=12, random_state=42)\n",
    "        est_list = [('lr', clf1), ('rf', clf2), ('gnb', clf3), ('xgb', clf4)]\n",
    "        logreg = ensemble.VotingClassifier(est_list,voting='soft',n_jobs=6)\n",
    "    else:\n",
    "        print(\"give correct model\")\n",
    "    print(logreg)\n",
    "    return logreg\n",
    "\n",
    "def get_feature(f_type=None,data=None):\n",
    "    if not f_type:\n",
    "        print(\"ERROR: Please specify a model type!\")\n",
    "        return None\n",
    "    if f_type == 'google_not_preprocess':\n",
    "        X,y=gen_data_google2(data)\n",
    "    elif f_type == 'word_to_vec_embed':\n",
    "        X,y=gen_data_embed(data)\n",
    "    elif f_type == 'google_preprocess':\n",
    "        X,y=gen_data_google(data)\n",
    "    elif f_type == 'tfidf_not_preprocess':\n",
    "        X,y=gen_data_new_tfidf2(data)\n",
    "    elif f_type == 'tfidf_preprocess':\n",
    "        X,y=gen_data_new_tfidf(data)\n",
    "    elif f_type == 'google_preprocess_tfidf_preprocess':\n",
    "        X,y=combine_tf_google_rem(data)\n",
    "    elif f_type == 'google_nopreprocess_tfidf_nopreprocess':\n",
    "        X,y=combine_tf_google_norem(data)\n",
    "    elif f_type == 'google_preprocess_tfidf_nopreprocess':\n",
    "        X,y=combine_tf_norem_google_rem(data)\n",
    "    elif f_type == 'google_nopreprocess_tfidf_preprocess':\n",
    "        X,y=combine_tf_rem_google_norem(data)\n",
    "    elif f_type == 'google_nopreprocess_tfidf_preprocess_embed':\n",
    "        X,y=combine_tf_rem_google_norem_embed(data)\n",
    "    else:\n",
    "        print(\"give correct feature selection\")    \n",
    "    print(f_type)\n",
    "    return X,y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from imblearn.combine import SMOTETomek \n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "from sklearn.model_selection import StratifiedKFold as skf\n",
    "\n",
    "def binny_classifier_run(X,y,model,model_name,label_map,img_name,report_name,save_model=False):\n",
    "    Classifier_Train_X = np.array(X, copy=False)\n",
    "    Classifier_Train_Y = y\n",
    "  \n",
    "    temp=[]\n",
    "    for data in Classifier_Train_Y:\n",
    "        temp.append(label_map[data])\n",
    "#     print(Classifier_Train_Y)\n",
    "    Classifier_Train_Y=np.array(temp)\n",
    "    \n",
    "    model_featureSelection = SelectFromModel(ensemble.RandomForestClassifier(n_estimators=50, class_weight='balanced', \n",
    "                                                                                     n_jobs=12, max_depth=3))\n",
    "    print('Before Num features=',Classifier_Train_X.shape[1], Counter(Classifier_Train_Y))\n",
    "    Classifier_Train_X = model_featureSelection.fit_transform(Classifier_Train_X,Classifier_Train_Y)\n",
    "    print('After Num features=',Classifier_Train_X.shape[1])\n",
    "\n",
    "    \n",
    "    \n",
    "    if(save_model==True):\n",
    "        Classifier=model\n",
    "        Classifier.fit(Classifier_Train_X, Classifier_Train_Y)\n",
    "        filename = 'taskB1/'+model_name+'_task_2.joblib.pkl'\n",
    "        joblib.dump(Classifier, filename, compress=9)\n",
    "        filename1 = 'taskB1/'+model_name+'_select_features_task2.joblib.pkl'\n",
    "        joblib.dump(model_featureSelection, filename1, compress=9)\n",
    "    else:\n",
    "        from sklearn.model_selection import KFold\n",
    "        kf = skf(n_splits=10)\n",
    "        y_total_preds=[] \n",
    "        y_total=[]\n",
    "        count=0\n",
    "\n",
    "        for train_index, test_index in kf.split(Classifier_Train_X,Classifier_Train_Y):\n",
    "            X_train, X_test = Classifier_Train_X[train_index], Classifier_Train_X[test_index]\n",
    "            y_train, y_test = Classifier_Train_Y[train_index], Classifier_Train_Y[test_index]\n",
    "            classifier=model \n",
    "            classifier.fit(X_train,y_train)\n",
    "            y_preds = classifier.predict(X_test)\n",
    "            for ele in y_test:\n",
    "                y_total.append(ele)\n",
    "            for ele in y_preds:\n",
    "                if(model_name=='Catboost'):\n",
    "                    y_total_preds.append(ele[0])\n",
    "                else:\n",
    "                    y_total_preds.append(ele)\n",
    "                    \n",
    "            y_pred_train = classifier.predict(X_train)\n",
    "            count=count+1       \n",
    "            print('accuracy_train:',accuracy_score(y_train, y_pred_train),'accuracy_test:',accuracy_score(y_test, y_preds))\n",
    "            print('TRAINING:')\n",
    "            print(classification_report( y_train, y_pred_train ))\n",
    "            print(\"TESTING:\")\n",
    "            print(classification_report( y_test, y_preds ))\n",
    "\n",
    "        report = classification_report( y_total, y_total_preds )\n",
    "        cm=confusion_matrix(y_total, y_total_preds)\n",
    "        plt=plot_confusion_matrix(cm,normalize= True,target_names = ['discredit','sexual_harassment','stereotype','dominance','derailing'],title = \"Confusion Matrix\")\n",
    "        plt.savefig('task2'+model_name+'_'+img_name)\n",
    "        print(model)\n",
    "        print(report)\n",
    "        print(accuracy_score(y_total, y_total_preds))\n",
    "        df_result=pandas_classification_report(y_total,y_total_preds)\n",
    "        df_result.to_csv('task2'+model_name+'_'+report_name,  sep=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier_model = 'gaussian'\n",
    "feature_model = 'google_nopreprocess_tfidf_preprocess_embed'\n",
    "img_name = 'cm.png'\n",
    "report_name = 'report.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ending\n",
      "google_nopreprocess_tfidf_preprocess_embed\n"
     ]
    }
   ],
   "source": [
    "data_name= 'pd_train_category'\n",
    "\n",
    "if(data_name=='pd_train_binary'):\n",
    "    X,y=get_feature(f_type=feature_model,data=pd_train_binary)\n",
    "    label_map = {\n",
    "             1: 1,\n",
    "             0: 0\n",
    "                 }\n",
    "elif(data_name=='pd_train_category'):\n",
    "    X,y=get_feature(f_type=feature_model,data=pd_train_category)\n",
    "    label_map = {\n",
    "            'discredit': 0,\n",
    "            'sexual_harassment': 1,\n",
    "            'stereotype': 2,\n",
    "            'dominance': 3,\n",
    "            'derailing': 4\n",
    "        }\n",
    "elif(data_name=='pd_train_target'):\n",
    "    X,y=get_feature(f_type=feature_model,data=pd_train_target)\n",
    "    label_map = {\n",
    "             'active': 1,\n",
    "             'passive': 0\n",
    "         }\n",
    "\n",
    "else:\n",
    "    print('give correct data')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB(priors=None)\n"
     ]
    }
   ],
   "source": [
    "model=get_model(m_type=classifier_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<catboost.core.CatBoostClassifier object at 0x7f1991ad6c18>\n",
      "Before Num features= 15712 Counter({0: 1014, 1: 352, 2: 179, 3: 148, 4: 92})\n",
      "After Num features= 277\n",
      "0:\tlearn: -1.5955220\ttotal: 118ms\tremaining: 1m 57s\n",
      "1:\tlearn: -1.5806177\ttotal: 211ms\tremaining: 1m 45s\n",
      "2:\tlearn: -1.5668825\ttotal: 316ms\tremaining: 1m 44s\n",
      "3:\tlearn: -1.5572618\ttotal: 409ms\tremaining: 1m 41s\n",
      "4:\tlearn: -1.5432442\ttotal: 501ms\tremaining: 1m 39s\n",
      "5:\tlearn: -1.5316033\ttotal: 592ms\tremaining: 1m 38s\n",
      "6:\tlearn: -1.5220850\ttotal: 672ms\tremaining: 1m 35s\n",
      "7:\tlearn: -1.5113581\ttotal: 766ms\tremaining: 1m 34s\n",
      "8:\tlearn: -1.5012559\ttotal: 851ms\tremaining: 1m 33s\n",
      "9:\tlearn: -1.4895076\ttotal: 939ms\tremaining: 1m 32s\n",
      "10:\tlearn: -1.4823338\ttotal: 1.02s\tremaining: 1m 31s\n",
      "11:\tlearn: -1.4721065\ttotal: 1.11s\tremaining: 1m 31s\n",
      "12:\tlearn: -1.4629189\ttotal: 1.2s\tremaining: 1m 30s\n",
      "13:\tlearn: -1.4527619\ttotal: 1.27s\tremaining: 1m 29s\n",
      "14:\tlearn: -1.4419376\ttotal: 1.37s\tremaining: 1m 29s\n",
      "15:\tlearn: -1.4322653\ttotal: 1.45s\tremaining: 1m 29s\n",
      "16:\tlearn: -1.4240560\ttotal: 1.53s\tremaining: 1m 28s\n",
      "17:\tlearn: -1.4162808\ttotal: 1.62s\tremaining: 1m 28s\n",
      "18:\tlearn: -1.4068702\ttotal: 1.71s\tremaining: 1m 28s\n",
      "19:\tlearn: -1.4003492\ttotal: 1.79s\tremaining: 1m 27s\n",
      "20:\tlearn: -1.3897960\ttotal: 1.89s\tremaining: 1m 27s\n",
      "21:\tlearn: -1.3815590\ttotal: 1.97s\tremaining: 1m 27s\n",
      "22:\tlearn: -1.3744041\ttotal: 2.06s\tremaining: 1m 27s\n",
      "23:\tlearn: -1.3678550\ttotal: 2.14s\tremaining: 1m 27s\n",
      "24:\tlearn: -1.3618545\ttotal: 2.22s\tremaining: 1m 26s\n",
      "25:\tlearn: -1.3567975\ttotal: 2.31s\tremaining: 1m 26s\n",
      "26:\tlearn: -1.3509106\ttotal: 2.39s\tremaining: 1m 26s\n",
      "27:\tlearn: -1.3445519\ttotal: 2.47s\tremaining: 1m 25s\n",
      "28:\tlearn: -1.3387220\ttotal: 2.55s\tremaining: 1m 25s\n",
      "29:\tlearn: -1.3303850\ttotal: 2.65s\tremaining: 1m 25s\n",
      "30:\tlearn: -1.3259932\ttotal: 2.73s\tremaining: 1m 25s\n",
      "31:\tlearn: -1.3200630\ttotal: 2.82s\tremaining: 1m 25s\n",
      "32:\tlearn: -1.3147358\ttotal: 2.9s\tremaining: 1m 25s\n",
      "33:\tlearn: -1.3096538\ttotal: 2.99s\tremaining: 1m 24s\n",
      "34:\tlearn: -1.3039297\ttotal: 3.06s\tremaining: 1m 24s\n",
      "35:\tlearn: -1.2985252\ttotal: 3.14s\tremaining: 1m 24s\n",
      "36:\tlearn: -1.2942312\ttotal: 3.22s\tremaining: 1m 23s\n",
      "37:\tlearn: -1.2879750\ttotal: 3.31s\tremaining: 1m 23s\n",
      "38:\tlearn: -1.2818247\ttotal: 3.39s\tremaining: 1m 23s\n",
      "39:\tlearn: -1.2780310\ttotal: 3.48s\tremaining: 1m 23s\n",
      "40:\tlearn: -1.2723422\ttotal: 3.56s\tremaining: 1m 23s\n",
      "41:\tlearn: -1.2660420\ttotal: 3.65s\tremaining: 1m 23s\n",
      "42:\tlearn: -1.2602707\ttotal: 3.73s\tremaining: 1m 23s\n",
      "43:\tlearn: -1.2541021\ttotal: 3.82s\tremaining: 1m 23s\n",
      "44:\tlearn: -1.2491850\ttotal: 3.9s\tremaining: 1m 22s\n",
      "45:\tlearn: -1.2437584\ttotal: 3.98s\tremaining: 1m 22s\n",
      "46:\tlearn: -1.2377763\ttotal: 4.07s\tremaining: 1m 22s\n",
      "47:\tlearn: -1.2311411\ttotal: 4.17s\tremaining: 1m 22s\n",
      "48:\tlearn: -1.2250816\ttotal: 4.26s\tremaining: 1m 22s\n",
      "49:\tlearn: -1.2204066\ttotal: 4.34s\tremaining: 1m 22s\n",
      "50:\tlearn: -1.2151491\ttotal: 4.43s\tremaining: 1m 22s\n",
      "51:\tlearn: -1.2123489\ttotal: 4.51s\tremaining: 1m 22s\n",
      "52:\tlearn: -1.2076921\ttotal: 4.6s\tremaining: 1m 22s\n",
      "53:\tlearn: -1.2027724\ttotal: 4.68s\tremaining: 1m 22s\n",
      "54:\tlearn: -1.1996238\ttotal: 4.76s\tremaining: 1m 21s\n",
      "55:\tlearn: -1.1945288\ttotal: 4.84s\tremaining: 1m 21s\n",
      "56:\tlearn: -1.1913937\ttotal: 4.93s\tremaining: 1m 21s\n",
      "57:\tlearn: -1.1872439\ttotal: 5.02s\tremaining: 1m 21s\n",
      "58:\tlearn: -1.1840332\ttotal: 5.11s\tremaining: 1m 21s\n",
      "59:\tlearn: -1.1806409\ttotal: 5.19s\tremaining: 1m 21s\n",
      "60:\tlearn: -1.1767056\ttotal: 5.27s\tremaining: 1m 21s\n",
      "61:\tlearn: -1.1730937\ttotal: 5.35s\tremaining: 1m 20s\n",
      "62:\tlearn: -1.1697324\ttotal: 5.43s\tremaining: 1m 20s\n",
      "63:\tlearn: -1.1643592\ttotal: 5.52s\tremaining: 1m 20s\n",
      "64:\tlearn: -1.1592731\ttotal: 5.61s\tremaining: 1m 20s\n",
      "65:\tlearn: -1.1562684\ttotal: 5.68s\tremaining: 1m 20s\n",
      "66:\tlearn: -1.1511494\ttotal: 5.78s\tremaining: 1m 20s\n",
      "67:\tlearn: -1.1471415\ttotal: 5.86s\tremaining: 1m 20s\n",
      "68:\tlearn: -1.1412678\ttotal: 5.96s\tremaining: 1m 20s\n",
      "69:\tlearn: -1.1372983\ttotal: 6.04s\tremaining: 1m 20s\n",
      "70:\tlearn: -1.1337656\ttotal: 6.13s\tremaining: 1m 20s\n",
      "71:\tlearn: -1.1300113\ttotal: 6.22s\tremaining: 1m 20s\n",
      "72:\tlearn: -1.1275419\ttotal: 6.29s\tremaining: 1m 19s\n",
      "73:\tlearn: -1.1239967\ttotal: 6.38s\tremaining: 1m 19s\n",
      "74:\tlearn: -1.1219093\ttotal: 6.46s\tremaining: 1m 19s\n",
      "75:\tlearn: -1.1193398\ttotal: 6.53s\tremaining: 1m 19s\n",
      "76:\tlearn: -1.1167229\ttotal: 6.61s\tremaining: 1m 19s\n",
      "77:\tlearn: -1.1131635\ttotal: 6.69s\tremaining: 1m 19s\n",
      "78:\tlearn: -1.1097353\ttotal: 6.76s\tremaining: 1m 18s\n",
      "79:\tlearn: -1.1067364\ttotal: 6.85s\tremaining: 1m 18s\n",
      "80:\tlearn: -1.1042714\ttotal: 6.93s\tremaining: 1m 18s\n",
      "81:\tlearn: -1.1029837\ttotal: 7.01s\tremaining: 1m 18s\n",
      "82:\tlearn: -1.0989689\ttotal: 7.08s\tremaining: 1m 18s\n",
      "83:\tlearn: -1.0956707\ttotal: 7.18s\tremaining: 1m 18s\n",
      "84:\tlearn: -1.0938097\ttotal: 7.25s\tremaining: 1m 18s\n",
      "85:\tlearn: -1.0891739\ttotal: 7.34s\tremaining: 1m 18s\n",
      "86:\tlearn: -1.0871941\ttotal: 7.42s\tremaining: 1m 17s\n",
      "87:\tlearn: -1.0824165\ttotal: 7.52s\tremaining: 1m 17s\n",
      "88:\tlearn: -1.0792923\ttotal: 7.6s\tremaining: 1m 17s\n",
      "89:\tlearn: -1.0760988\ttotal: 7.69s\tremaining: 1m 17s\n",
      "90:\tlearn: -1.0730866\ttotal: 7.77s\tremaining: 1m 17s\n",
      "91:\tlearn: -1.0715596\ttotal: 7.84s\tremaining: 1m 17s\n",
      "92:\tlearn: -1.0685976\ttotal: 7.93s\tremaining: 1m 17s\n",
      "93:\tlearn: -1.0657229\ttotal: 8.02s\tremaining: 1m 17s\n",
      "94:\tlearn: -1.0623877\ttotal: 8.11s\tremaining: 1m 17s\n",
      "95:\tlearn: -1.0598098\ttotal: 8.19s\tremaining: 1m 17s\n",
      "96:\tlearn: -1.0566195\ttotal: 8.27s\tremaining: 1m 16s\n",
      "97:\tlearn: -1.0542346\ttotal: 8.35s\tremaining: 1m 16s\n",
      "98:\tlearn: -1.0515142\ttotal: 8.43s\tremaining: 1m 16s\n",
      "99:\tlearn: -1.0488336\ttotal: 8.51s\tremaining: 1m 16s\n",
      "100:\tlearn: -1.0462928\ttotal: 8.6s\tremaining: 1m 16s\n",
      "101:\tlearn: -1.0432904\ttotal: 8.68s\tremaining: 1m 16s\n",
      "102:\tlearn: -1.0402732\ttotal: 8.77s\tremaining: 1m 16s\n",
      "103:\tlearn: -1.0372825\ttotal: 8.86s\tremaining: 1m 16s\n",
      "104:\tlearn: -1.0342307\ttotal: 8.94s\tremaining: 1m 16s\n",
      "105:\tlearn: -1.0314301\ttotal: 9.03s\tremaining: 1m 16s\n",
      "106:\tlearn: -1.0293796\ttotal: 9.11s\tremaining: 1m 16s\n",
      "107:\tlearn: -1.0267395\ttotal: 9.19s\tremaining: 1m 15s\n",
      "108:\tlearn: -1.0227176\ttotal: 9.28s\tremaining: 1m 15s\n",
      "109:\tlearn: -1.0200121\ttotal: 9.37s\tremaining: 1m 15s\n",
      "110:\tlearn: -1.0168441\ttotal: 9.44s\tremaining: 1m 15s\n",
      "111:\tlearn: -1.0150624\ttotal: 9.52s\tremaining: 1m 15s\n",
      "112:\tlearn: -1.0129815\ttotal: 9.6s\tremaining: 1m 15s\n",
      "113:\tlearn: -1.0105207\ttotal: 9.68s\tremaining: 1m 15s\n",
      "114:\tlearn: -1.0081214\ttotal: 9.75s\tremaining: 1m 15s\n",
      "115:\tlearn: -1.0062885\ttotal: 9.84s\tremaining: 1m 14s\n",
      "116:\tlearn: -1.0018893\ttotal: 9.94s\tremaining: 1m 15s\n",
      "117:\tlearn: -0.9982209\ttotal: 10s\tremaining: 1m 14s\n",
      "118:\tlearn: -0.9953375\ttotal: 10.1s\tremaining: 1m 14s\n",
      "119:\tlearn: -0.9936879\ttotal: 10.2s\tremaining: 1m 14s\n",
      "120:\tlearn: -0.9918142\ttotal: 10.3s\tremaining: 1m 14s\n",
      "121:\tlearn: -0.9898903\ttotal: 10.4s\tremaining: 1m 14s\n",
      "122:\tlearn: -0.9862195\ttotal: 10.4s\tremaining: 1m 14s\n",
      "123:\tlearn: -0.9838772\ttotal: 10.5s\tremaining: 1m 14s\n",
      "124:\tlearn: -0.9798511\ttotal: 10.6s\tremaining: 1m 14s\n",
      "125:\tlearn: -0.9776502\ttotal: 10.7s\tremaining: 1m 14s\n",
      "126:\tlearn: -0.9754099\ttotal: 10.8s\tremaining: 1m 14s\n",
      "127:\tlearn: -0.9730086\ttotal: 10.9s\tremaining: 1m 14s\n",
      "128:\tlearn: -0.9720343\ttotal: 10.9s\tremaining: 1m 13s\n",
      "129:\tlearn: -0.9680057\ttotal: 11s\tremaining: 1m 13s\n",
      "130:\tlearn: -0.9665628\ttotal: 11.1s\tremaining: 1m 13s\n",
      "131:\tlearn: -0.9639549\ttotal: 11.2s\tremaining: 1m 13s\n",
      "132:\tlearn: -0.9608972\ttotal: 11.3s\tremaining: 1m 13s\n",
      "133:\tlearn: -0.9583334\ttotal: 11.4s\tremaining: 1m 13s\n",
      "134:\tlearn: -0.9564703\ttotal: 11.4s\tremaining: 1m 13s\n",
      "135:\tlearn: -0.9538326\ttotal: 11.5s\tremaining: 1m 13s\n",
      "136:\tlearn: -0.9504170\ttotal: 11.6s\tremaining: 1m 13s\n",
      "137:\tlearn: -0.9473915\ttotal: 11.7s\tremaining: 1m 13s\n",
      "138:\tlearn: -0.9439006\ttotal: 11.8s\tremaining: 1m 13s\n",
      "139:\tlearn: -0.9417715\ttotal: 11.9s\tremaining: 1m 13s\n",
      "140:\tlearn: -0.9392783\ttotal: 12s\tremaining: 1m 13s\n",
      "141:\tlearn: -0.9367234\ttotal: 12.1s\tremaining: 1m 12s\n",
      "142:\tlearn: -0.9334523\ttotal: 12.2s\tremaining: 1m 12s\n",
      "143:\tlearn: -0.9313744\ttotal: 12.2s\tremaining: 1m 12s\n",
      "144:\tlearn: -0.9286952\ttotal: 12.3s\tremaining: 1m 12s\n",
      "145:\tlearn: -0.9268715\ttotal: 12.4s\tremaining: 1m 12s\n",
      "146:\tlearn: -0.9243579\ttotal: 12.5s\tremaining: 1m 12s\n",
      "147:\tlearn: -0.9221747\ttotal: 12.6s\tremaining: 1m 12s\n",
      "148:\tlearn: -0.9194592\ttotal: 12.6s\tremaining: 1m 12s\n",
      "149:\tlearn: -0.9178860\ttotal: 12.7s\tremaining: 1m 12s\n",
      "150:\tlearn: -0.9154424\ttotal: 12.8s\tremaining: 1m 12s\n",
      "151:\tlearn: -0.9134250\ttotal: 12.9s\tremaining: 1m 11s\n",
      "152:\tlearn: -0.9116690\ttotal: 13s\tremaining: 1m 11s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153:\tlearn: -0.9084764\ttotal: 13.1s\tremaining: 1m 11s\n",
      "154:\tlearn: -0.9064558\ttotal: 13.1s\tremaining: 1m 11s\n",
      "155:\tlearn: -0.9047067\ttotal: 13.2s\tremaining: 1m 11s\n",
      "156:\tlearn: -0.9024586\ttotal: 13.3s\tremaining: 1m 11s\n",
      "157:\tlearn: -0.9000893\ttotal: 13.4s\tremaining: 1m 11s\n",
      "158:\tlearn: -0.8977697\ttotal: 13.5s\tremaining: 1m 11s\n",
      "159:\tlearn: -0.8960987\ttotal: 13.6s\tremaining: 1m 11s\n",
      "160:\tlearn: -0.8938402\ttotal: 13.7s\tremaining: 1m 11s\n",
      "161:\tlearn: -0.8904861\ttotal: 13.8s\tremaining: 1m 11s\n",
      "162:\tlearn: -0.8888697\ttotal: 13.8s\tremaining: 1m 11s\n",
      "163:\tlearn: -0.8859375\ttotal: 13.9s\tremaining: 1m 10s\n",
      "164:\tlearn: -0.8844633\ttotal: 14s\tremaining: 1m 10s\n",
      "165:\tlearn: -0.8825860\ttotal: 14.1s\tremaining: 1m 10s\n",
      "166:\tlearn: -0.8808846\ttotal: 14.2s\tremaining: 1m 10s\n",
      "167:\tlearn: -0.8794049\ttotal: 14.2s\tremaining: 1m 10s\n",
      "168:\tlearn: -0.8778777\ttotal: 14.3s\tremaining: 1m 10s\n",
      "169:\tlearn: -0.8763500\ttotal: 14.4s\tremaining: 1m 10s\n",
      "170:\tlearn: -0.8748947\ttotal: 14.5s\tremaining: 1m 10s\n",
      "171:\tlearn: -0.8739102\ttotal: 14.6s\tremaining: 1m 10s\n",
      "172:\tlearn: -0.8714902\ttotal: 14.6s\tremaining: 1m 10s\n",
      "173:\tlearn: -0.8690697\ttotal: 14.7s\tremaining: 1m 9s\n",
      "174:\tlearn: -0.8646893\ttotal: 14.8s\tremaining: 1m 9s\n",
      "175:\tlearn: -0.8636265\ttotal: 14.9s\tremaining: 1m 9s\n",
      "176:\tlearn: -0.8623764\ttotal: 15s\tremaining: 1m 9s\n",
      "177:\tlearn: -0.8598909\ttotal: 15.1s\tremaining: 1m 9s\n",
      "178:\tlearn: -0.8573396\ttotal: 15.2s\tremaining: 1m 9s\n",
      "179:\tlearn: -0.8559186\ttotal: 15.3s\tremaining: 1m 9s\n",
      "180:\tlearn: -0.8530283\ttotal: 15.3s\tremaining: 1m 9s\n",
      "181:\tlearn: -0.8504550\ttotal: 15.4s\tremaining: 1m 9s\n",
      "182:\tlearn: -0.8487285\ttotal: 15.5s\tremaining: 1m 9s\n",
      "183:\tlearn: -0.8475999\ttotal: 15.6s\tremaining: 1m 9s\n",
      "184:\tlearn: -0.8459083\ttotal: 15.7s\tremaining: 1m 9s\n",
      "185:\tlearn: -0.8442662\ttotal: 15.8s\tremaining: 1m 8s\n",
      "186:\tlearn: -0.8423313\ttotal: 15.8s\tremaining: 1m 8s\n",
      "187:\tlearn: -0.8397805\ttotal: 15.9s\tremaining: 1m 8s\n",
      "188:\tlearn: -0.8379302\ttotal: 16s\tremaining: 1m 8s\n",
      "189:\tlearn: -0.8365600\ttotal: 16.1s\tremaining: 1m 8s\n",
      "190:\tlearn: -0.8352393\ttotal: 16.2s\tremaining: 1m 8s\n",
      "191:\tlearn: -0.8338985\ttotal: 16.3s\tremaining: 1m 8s\n",
      "192:\tlearn: -0.8320718\ttotal: 16.4s\tremaining: 1m 8s\n",
      "193:\tlearn: -0.8311602\ttotal: 16.4s\tremaining: 1m 8s\n",
      "194:\tlearn: -0.8292967\ttotal: 16.5s\tremaining: 1m 8s\n",
      "195:\tlearn: -0.8276647\ttotal: 16.6s\tremaining: 1m 8s\n",
      "196:\tlearn: -0.8252219\ttotal: 16.7s\tremaining: 1m 8s\n",
      "197:\tlearn: -0.8226347\ttotal: 16.8s\tremaining: 1m 8s\n",
      "198:\tlearn: -0.8211441\ttotal: 16.9s\tremaining: 1m 8s\n",
      "199:\tlearn: -0.8176346\ttotal: 17s\tremaining: 1m 7s\n",
      "200:\tlearn: -0.8154081\ttotal: 17.1s\tremaining: 1m 7s\n",
      "201:\tlearn: -0.8137931\ttotal: 17.2s\tremaining: 1m 7s\n",
      "202:\tlearn: -0.8125622\ttotal: 17.2s\tremaining: 1m 7s\n",
      "203:\tlearn: -0.8104668\ttotal: 17.3s\tremaining: 1m 7s\n",
      "204:\tlearn: -0.8091838\ttotal: 17.4s\tremaining: 1m 7s\n",
      "205:\tlearn: -0.8069634\ttotal: 17.5s\tremaining: 1m 7s\n",
      "206:\tlearn: -0.8043500\ttotal: 17.6s\tremaining: 1m 7s\n",
      "207:\tlearn: -0.8029616\ttotal: 17.7s\tremaining: 1m 7s\n",
      "208:\tlearn: -0.8011990\ttotal: 17.7s\tremaining: 1m 7s\n",
      "209:\tlearn: -0.7982201\ttotal: 17.8s\tremaining: 1m 7s\n",
      "210:\tlearn: -0.7968227\ttotal: 17.9s\tremaining: 1m 7s\n",
      "211:\tlearn: -0.7947293\ttotal: 18s\tremaining: 1m 6s\n",
      "212:\tlearn: -0.7939454\ttotal: 18.1s\tremaining: 1m 6s\n",
      "213:\tlearn: -0.7925014\ttotal: 18.2s\tremaining: 1m 6s\n",
      "214:\tlearn: -0.7911283\ttotal: 18.3s\tremaining: 1m 6s\n",
      "215:\tlearn: -0.7894993\ttotal: 18.3s\tremaining: 1m 6s\n",
      "216:\tlearn: -0.7873409\ttotal: 18.4s\tremaining: 1m 6s\n",
      "217:\tlearn: -0.7858867\ttotal: 18.5s\tremaining: 1m 6s\n",
      "218:\tlearn: -0.7840710\ttotal: 18.6s\tremaining: 1m 6s\n",
      "219:\tlearn: -0.7817406\ttotal: 18.7s\tremaining: 1m 6s\n",
      "220:\tlearn: -0.7810408\ttotal: 18.7s\tremaining: 1m 6s\n",
      "221:\tlearn: -0.7795589\ttotal: 18.8s\tremaining: 1m 5s\n",
      "222:\tlearn: -0.7776057\ttotal: 18.9s\tremaining: 1m 5s\n",
      "223:\tlearn: -0.7757866\ttotal: 19s\tremaining: 1m 5s\n",
      "224:\tlearn: -0.7735025\ttotal: 19.1s\tremaining: 1m 5s\n",
      "225:\tlearn: -0.7706684\ttotal: 19.2s\tremaining: 1m 5s\n",
      "226:\tlearn: -0.7697438\ttotal: 19.3s\tremaining: 1m 5s\n",
      "227:\tlearn: -0.7686040\ttotal: 19.4s\tremaining: 1m 5s\n",
      "228:\tlearn: -0.7674639\ttotal: 19.4s\tremaining: 1m 5s\n",
      "229:\tlearn: -0.7653699\ttotal: 19.5s\tremaining: 1m 5s\n",
      "230:\tlearn: -0.7636931\ttotal: 19.6s\tremaining: 1m 5s\n",
      "231:\tlearn: -0.7615050\ttotal: 19.7s\tremaining: 1m 5s\n",
      "232:\tlearn: -0.7592623\ttotal: 19.8s\tremaining: 1m 5s\n",
      "233:\tlearn: -0.7576883\ttotal: 19.9s\tremaining: 1m 5s\n",
      "234:\tlearn: -0.7566391\ttotal: 19.9s\tremaining: 1m 4s\n",
      "235:\tlearn: -0.7560250\ttotal: 20s\tremaining: 1m 4s\n",
      "236:\tlearn: -0.7545398\ttotal: 20.1s\tremaining: 1m 4s\n",
      "237:\tlearn: -0.7520154\ttotal: 20.2s\tremaining: 1m 4s\n",
      "238:\tlearn: -0.7508343\ttotal: 20.3s\tremaining: 1m 4s\n",
      "239:\tlearn: -0.7493826\ttotal: 20.4s\tremaining: 1m 4s\n",
      "240:\tlearn: -0.7480430\ttotal: 20.4s\tremaining: 1m 4s\n",
      "241:\tlearn: -0.7466467\ttotal: 20.5s\tremaining: 1m 4s\n",
      "242:\tlearn: -0.7449801\ttotal: 20.6s\tremaining: 1m 4s\n",
      "243:\tlearn: -0.7438309\ttotal: 20.7s\tremaining: 1m 4s\n",
      "244:\tlearn: -0.7421271\ttotal: 20.8s\tremaining: 1m 4s\n",
      "245:\tlearn: -0.7397778\ttotal: 20.9s\tremaining: 1m 3s\n",
      "246:\tlearn: -0.7378868\ttotal: 20.9s\tremaining: 1m 3s\n",
      "247:\tlearn: -0.7357079\ttotal: 21s\tremaining: 1m 3s\n",
      "248:\tlearn: -0.7336731\ttotal: 21.1s\tremaining: 1m 3s\n",
      "249:\tlearn: -0.7326036\ttotal: 21.2s\tremaining: 1m 3s\n",
      "250:\tlearn: -0.7307957\ttotal: 21.3s\tremaining: 1m 3s\n",
      "251:\tlearn: -0.7277043\ttotal: 21.4s\tremaining: 1m 3s\n",
      "252:\tlearn: -0.7262717\ttotal: 21.5s\tremaining: 1m 3s\n",
      "253:\tlearn: -0.7244890\ttotal: 21.6s\tremaining: 1m 3s\n",
      "254:\tlearn: -0.7234598\ttotal: 21.6s\tremaining: 1m 3s\n",
      "255:\tlearn: -0.7213862\ttotal: 21.7s\tremaining: 1m 3s\n",
      "256:\tlearn: -0.7189382\ttotal: 21.8s\tremaining: 1m 3s\n",
      "257:\tlearn: -0.7175747\ttotal: 21.9s\tremaining: 1m 2s\n",
      "258:\tlearn: -0.7167432\ttotal: 22s\tremaining: 1m 2s\n",
      "259:\tlearn: -0.7154807\ttotal: 22s\tremaining: 1m 2s\n",
      "260:\tlearn: -0.7144456\ttotal: 22.1s\tremaining: 1m 2s\n",
      "261:\tlearn: -0.7129401\ttotal: 22.2s\tremaining: 1m 2s\n",
      "262:\tlearn: -0.7111363\ttotal: 22.3s\tremaining: 1m 2s\n",
      "263:\tlearn: -0.7101321\ttotal: 22.4s\tremaining: 1m 2s\n",
      "264:\tlearn: -0.7082022\ttotal: 22.5s\tremaining: 1m 2s\n",
      "265:\tlearn: -0.7066318\ttotal: 22.5s\tremaining: 1m 2s\n",
      "266:\tlearn: -0.7050488\ttotal: 22.6s\tremaining: 1m 2s\n",
      "267:\tlearn: -0.7027532\ttotal: 22.7s\tremaining: 1m 2s\n",
      "268:\tlearn: -0.7013692\ttotal: 22.8s\tremaining: 1m 1s\n",
      "269:\tlearn: -0.7001802\ttotal: 22.9s\tremaining: 1m 1s\n",
      "270:\tlearn: -0.6986449\ttotal: 23s\tremaining: 1m 1s\n",
      "271:\tlearn: -0.6969335\ttotal: 23s\tremaining: 1m 1s\n",
      "272:\tlearn: -0.6952550\ttotal: 23.1s\tremaining: 1m 1s\n",
      "273:\tlearn: -0.6940694\ttotal: 23.2s\tremaining: 1m 1s\n",
      "274:\tlearn: -0.6917804\ttotal: 23.3s\tremaining: 1m 1s\n",
      "275:\tlearn: -0.6899349\ttotal: 23.4s\tremaining: 1m 1s\n",
      "276:\tlearn: -0.6871895\ttotal: 23.5s\tremaining: 1m 1s\n",
      "277:\tlearn: -0.6854433\ttotal: 23.6s\tremaining: 1m 1s\n",
      "278:\tlearn: -0.6831713\ttotal: 23.7s\tremaining: 1m 1s\n",
      "279:\tlearn: -0.6822691\ttotal: 23.7s\tremaining: 1m 1s\n",
      "280:\tlearn: -0.6802906\ttotal: 23.8s\tremaining: 1m\n",
      "281:\tlearn: -0.6780097\ttotal: 23.9s\tremaining: 1m\n",
      "282:\tlearn: -0.6771966\ttotal: 24s\tremaining: 1m\n",
      "283:\tlearn: -0.6751839\ttotal: 24.1s\tremaining: 1m\n",
      "284:\tlearn: -0.6739682\ttotal: 24.2s\tremaining: 1m\n",
      "285:\tlearn: -0.6724057\ttotal: 24.2s\tremaining: 1m\n",
      "286:\tlearn: -0.6705465\ttotal: 24.3s\tremaining: 1m\n",
      "287:\tlearn: -0.6688243\ttotal: 24.4s\tremaining: 1m\n",
      "288:\tlearn: -0.6668039\ttotal: 24.5s\tremaining: 1m\n",
      "289:\tlearn: -0.6660875\ttotal: 24.6s\tremaining: 1m\n",
      "290:\tlearn: -0.6641885\ttotal: 24.7s\tremaining: 1m\n",
      "291:\tlearn: -0.6625883\ttotal: 24.7s\tremaining: 1m\n",
      "292:\tlearn: -0.6612315\ttotal: 24.8s\tremaining: 59.9s\n",
      "293:\tlearn: -0.6600468\ttotal: 24.9s\tremaining: 59.8s\n",
      "294:\tlearn: -0.6580538\ttotal: 25s\tremaining: 59.7s\n",
      "295:\tlearn: -0.6567352\ttotal: 25.1s\tremaining: 59.6s\n",
      "296:\tlearn: -0.6556825\ttotal: 25.1s\tremaining: 59.5s\n",
      "297:\tlearn: -0.6549076\ttotal: 25.2s\tremaining: 59.4s\n",
      "298:\tlearn: -0.6536415\ttotal: 25.3s\tremaining: 59.3s\n",
      "299:\tlearn: -0.6513682\ttotal: 25.4s\tremaining: 59.2s\n",
      "300:\tlearn: -0.6504397\ttotal: 25.5s\tremaining: 59.1s\n",
      "301:\tlearn: -0.6486517\ttotal: 25.5s\tremaining: 59s\n",
      "302:\tlearn: -0.6469190\ttotal: 25.6s\tremaining: 59s\n",
      "303:\tlearn: -0.6454324\ttotal: 25.7s\tremaining: 58.9s\n",
      "304:\tlearn: -0.6440136\ttotal: 25.8s\tremaining: 58.8s\n",
      "305:\tlearn: -0.6423393\ttotal: 25.9s\tremaining: 58.7s\n",
      "306:\tlearn: -0.6414101\ttotal: 25.9s\tremaining: 58.6s\n",
      "307:\tlearn: -0.6395138\ttotal: 26s\tremaining: 58.5s\n",
      "308:\tlearn: -0.6384070\ttotal: 26.1s\tremaining: 58.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309:\tlearn: -0.6374366\ttotal: 26.2s\tremaining: 58.3s\n",
      "310:\tlearn: -0.6361518\ttotal: 26.3s\tremaining: 58.2s\n",
      "311:\tlearn: -0.6345903\ttotal: 26.3s\tremaining: 58.1s\n",
      "312:\tlearn: -0.6330021\ttotal: 26.4s\tremaining: 58s\n",
      "313:\tlearn: -0.6305330\ttotal: 26.5s\tremaining: 57.9s\n",
      "314:\tlearn: -0.6284950\ttotal: 26.6s\tremaining: 57.8s\n",
      "315:\tlearn: -0.6262111\ttotal: 26.7s\tremaining: 57.7s\n",
      "316:\tlearn: -0.6250200\ttotal: 26.8s\tremaining: 57.7s\n",
      "317:\tlearn: -0.6233500\ttotal: 26.8s\tremaining: 57.6s\n",
      "318:\tlearn: -0.6222518\ttotal: 26.9s\tremaining: 57.5s\n",
      "319:\tlearn: -0.6206391\ttotal: 27s\tremaining: 57.4s\n",
      "320:\tlearn: -0.6190048\ttotal: 27.1s\tremaining: 57.3s\n",
      "321:\tlearn: -0.6173044\ttotal: 27.2s\tremaining: 57.2s\n",
      "322:\tlearn: -0.6160394\ttotal: 27.3s\tremaining: 57.1s\n",
      "323:\tlearn: -0.6143378\ttotal: 27.3s\tremaining: 57s\n",
      "324:\tlearn: -0.6121662\ttotal: 27.4s\tremaining: 57s\n",
      "325:\tlearn: -0.6095717\ttotal: 27.5s\tremaining: 56.9s\n",
      "326:\tlearn: -0.6071806\ttotal: 27.6s\tremaining: 56.8s\n",
      "327:\tlearn: -0.6061632\ttotal: 27.7s\tremaining: 56.7s\n",
      "328:\tlearn: -0.6042304\ttotal: 27.8s\tremaining: 56.6s\n",
      "329:\tlearn: -0.6025950\ttotal: 27.8s\tremaining: 56.5s\n",
      "330:\tlearn: -0.6006725\ttotal: 27.9s\tremaining: 56.5s\n",
      "331:\tlearn: -0.5989906\ttotal: 28s\tremaining: 56.4s\n",
      "332:\tlearn: -0.5979623\ttotal: 28.1s\tremaining: 56.3s\n",
      "333:\tlearn: -0.5959178\ttotal: 28.2s\tremaining: 56.2s\n",
      "334:\tlearn: -0.5934192\ttotal: 28.3s\tremaining: 56.1s\n",
      "335:\tlearn: -0.5915454\ttotal: 28.4s\tremaining: 56s\n",
      "336:\tlearn: -0.5905862\ttotal: 28.4s\tremaining: 55.9s\n",
      "337:\tlearn: -0.5893489\ttotal: 28.5s\tremaining: 55.9s\n",
      "338:\tlearn: -0.5879442\ttotal: 28.6s\tremaining: 55.8s\n",
      "339:\tlearn: -0.5859523\ttotal: 28.7s\tremaining: 55.7s\n",
      "340:\tlearn: -0.5847575\ttotal: 28.8s\tremaining: 55.6s\n",
      "341:\tlearn: -0.5823606\ttotal: 28.9s\tremaining: 55.5s\n",
      "342:\tlearn: -0.5812081\ttotal: 28.9s\tremaining: 55.4s\n",
      "343:\tlearn: -0.5804311\ttotal: 29s\tremaining: 55.3s\n",
      "344:\tlearn: -0.5788339\ttotal: 29.1s\tremaining: 55.2s\n",
      "345:\tlearn: -0.5778865\ttotal: 29.2s\tremaining: 55.1s\n",
      "346:\tlearn: -0.5756190\ttotal: 29.3s\tremaining: 55.1s\n",
      "347:\tlearn: -0.5744299\ttotal: 29.3s\tremaining: 55s\n",
      "348:\tlearn: -0.5729917\ttotal: 29.4s\tremaining: 54.9s\n",
      "349:\tlearn: -0.5720438\ttotal: 29.5s\tremaining: 54.8s\n",
      "350:\tlearn: -0.5710516\ttotal: 29.6s\tremaining: 54.7s\n",
      "351:\tlearn: -0.5685953\ttotal: 29.7s\tremaining: 54.6s\n",
      "352:\tlearn: -0.5670454\ttotal: 29.8s\tremaining: 54.5s\n",
      "353:\tlearn: -0.5660305\ttotal: 29.8s\tremaining: 54.4s\n",
      "354:\tlearn: -0.5643582\ttotal: 29.9s\tremaining: 54.4s\n",
      "355:\tlearn: -0.5632224\ttotal: 30s\tremaining: 54.3s\n",
      "356:\tlearn: -0.5618786\ttotal: 30.1s\tremaining: 54.2s\n",
      "357:\tlearn: -0.5609632\ttotal: 30.2s\tremaining: 54.1s\n",
      "358:\tlearn: -0.5602600\ttotal: 30.2s\tremaining: 54s\n",
      "359:\tlearn: -0.5594190\ttotal: 30.3s\tremaining: 53.9s\n",
      "360:\tlearn: -0.5580650\ttotal: 30.4s\tremaining: 53.8s\n",
      "361:\tlearn: -0.5569277\ttotal: 30.5s\tremaining: 53.7s\n",
      "362:\tlearn: -0.5559161\ttotal: 30.6s\tremaining: 53.6s\n",
      "363:\tlearn: -0.5541310\ttotal: 30.6s\tremaining: 53.5s\n",
      "364:\tlearn: -0.5530569\ttotal: 30.7s\tremaining: 53.4s\n",
      "365:\tlearn: -0.5519913\ttotal: 30.8s\tremaining: 53.3s\n",
      "366:\tlearn: -0.5511351\ttotal: 30.9s\tremaining: 53.2s\n",
      "367:\tlearn: -0.5499003\ttotal: 30.9s\tremaining: 53.1s\n",
      "368:\tlearn: -0.5487060\ttotal: 31s\tremaining: 53s\n",
      "369:\tlearn: -0.5479419\ttotal: 31.1s\tremaining: 52.9s\n",
      "370:\tlearn: -0.5463289\ttotal: 31.2s\tremaining: 52.9s\n",
      "371:\tlearn: -0.5444121\ttotal: 31.3s\tremaining: 52.8s\n",
      "372:\tlearn: -0.5434110\ttotal: 31.3s\tremaining: 52.7s\n",
      "373:\tlearn: -0.5423998\ttotal: 31.4s\tremaining: 52.6s\n",
      "374:\tlearn: -0.5416128\ttotal: 31.5s\tremaining: 52.5s\n",
      "375:\tlearn: -0.5408513\ttotal: 31.6s\tremaining: 52.4s\n",
      "376:\tlearn: -0.5398909\ttotal: 31.6s\tremaining: 52.3s\n",
      "377:\tlearn: -0.5388412\ttotal: 31.7s\tremaining: 52.2s\n",
      "378:\tlearn: -0.5378572\ttotal: 31.8s\tremaining: 52.1s\n",
      "379:\tlearn: -0.5363008\ttotal: 31.9s\tremaining: 52s\n",
      "380:\tlearn: -0.5355096\ttotal: 32s\tremaining: 51.9s\n",
      "381:\tlearn: -0.5347309\ttotal: 32s\tremaining: 51.8s\n",
      "382:\tlearn: -0.5338518\ttotal: 32.1s\tremaining: 51.7s\n",
      "383:\tlearn: -0.5328350\ttotal: 32.2s\tremaining: 51.6s\n",
      "384:\tlearn: -0.5305422\ttotal: 32.3s\tremaining: 51.6s\n",
      "385:\tlearn: -0.5289697\ttotal: 32.4s\tremaining: 51.5s\n",
      "386:\tlearn: -0.5274336\ttotal: 32.5s\tremaining: 51.4s\n",
      "387:\tlearn: -0.5259566\ttotal: 32.5s\tremaining: 51.3s\n",
      "388:\tlearn: -0.5249362\ttotal: 32.6s\tremaining: 51.3s\n",
      "389:\tlearn: -0.5244158\ttotal: 32.7s\tremaining: 51.1s\n",
      "390:\tlearn: -0.5232729\ttotal: 32.8s\tremaining: 51.1s\n",
      "391:\tlearn: -0.5219228\ttotal: 32.9s\tremaining: 51s\n",
      "392:\tlearn: -0.5211664\ttotal: 32.9s\tremaining: 50.9s\n",
      "393:\tlearn: -0.5196347\ttotal: 33s\tremaining: 50.8s\n",
      "394:\tlearn: -0.5187107\ttotal: 33.1s\tremaining: 50.7s\n",
      "395:\tlearn: -0.5180206\ttotal: 33.2s\tremaining: 50.6s\n",
      "396:\tlearn: -0.5168853\ttotal: 33.3s\tremaining: 50.5s\n",
      "397:\tlearn: -0.5158989\ttotal: 33.3s\tremaining: 50.4s\n",
      "398:\tlearn: -0.5148168\ttotal: 33.4s\tremaining: 50.3s\n",
      "399:\tlearn: -0.5139040\ttotal: 33.5s\tremaining: 50.2s\n",
      "400:\tlearn: -0.5132363\ttotal: 33.6s\tremaining: 50.1s\n",
      "401:\tlearn: -0.5123323\ttotal: 33.6s\tremaining: 50s\n",
      "402:\tlearn: -0.5104620\ttotal: 33.7s\tremaining: 50s\n",
      "403:\tlearn: -0.5092605\ttotal: 33.8s\tremaining: 49.9s\n",
      "404:\tlearn: -0.5081436\ttotal: 33.9s\tremaining: 49.8s\n",
      "405:\tlearn: -0.5072476\ttotal: 34s\tremaining: 49.7s\n",
      "406:\tlearn: -0.5066681\ttotal: 34s\tremaining: 49.6s\n",
      "407:\tlearn: -0.5059456\ttotal: 34.1s\tremaining: 49.5s\n",
      "408:\tlearn: -0.5049484\ttotal: 34.2s\tremaining: 49.4s\n",
      "409:\tlearn: -0.5039661\ttotal: 34.3s\tremaining: 49.3s\n",
      "410:\tlearn: -0.5026553\ttotal: 34.4s\tremaining: 49.2s\n",
      "411:\tlearn: -0.5016132\ttotal: 34.4s\tremaining: 49.2s\n",
      "412:\tlearn: -0.5002258\ttotal: 34.5s\tremaining: 49.1s\n",
      "413:\tlearn: -0.4993740\ttotal: 34.6s\tremaining: 49s\n",
      "414:\tlearn: -0.4980754\ttotal: 34.7s\tremaining: 48.9s\n",
      "415:\tlearn: -0.4972082\ttotal: 34.8s\tremaining: 48.8s\n",
      "416:\tlearn: -0.4965543\ttotal: 34.8s\tremaining: 48.7s\n",
      "417:\tlearn: -0.4953784\ttotal: 34.9s\tremaining: 48.6s\n",
      "418:\tlearn: -0.4936543\ttotal: 35s\tremaining: 48.5s\n",
      "419:\tlearn: -0.4931524\ttotal: 35.1s\tremaining: 48.4s\n",
      "420:\tlearn: -0.4922243\ttotal: 35.2s\tremaining: 48.4s\n",
      "421:\tlearn: -0.4910116\ttotal: 35.3s\tremaining: 48.3s\n",
      "422:\tlearn: -0.4900755\ttotal: 35.3s\tremaining: 48.2s\n",
      "423:\tlearn: -0.4892262\ttotal: 35.4s\tremaining: 48.1s\n",
      "424:\tlearn: -0.4888438\ttotal: 35.5s\tremaining: 48s\n",
      "425:\tlearn: -0.4882082\ttotal: 35.6s\tremaining: 47.9s\n",
      "426:\tlearn: -0.4871081\ttotal: 35.6s\tremaining: 47.8s\n",
      "427:\tlearn: -0.4855671\ttotal: 35.7s\tremaining: 47.7s\n",
      "428:\tlearn: -0.4837644\ttotal: 35.8s\tremaining: 47.7s\n",
      "429:\tlearn: -0.4813222\ttotal: 35.9s\tremaining: 47.6s\n",
      "430:\tlearn: -0.4805403\ttotal: 36s\tremaining: 47.5s\n",
      "431:\tlearn: -0.4800265\ttotal: 36.1s\tremaining: 47.4s\n",
      "432:\tlearn: -0.4794121\ttotal: 36.1s\tremaining: 47.3s\n",
      "433:\tlearn: -0.4789377\ttotal: 36.2s\tremaining: 47.2s\n",
      "434:\tlearn: -0.4771238\ttotal: 36.3s\tremaining: 47.2s\n",
      "435:\tlearn: -0.4755478\ttotal: 36.4s\tremaining: 47.1s\n",
      "436:\tlearn: -0.4740872\ttotal: 36.5s\tremaining: 47s\n",
      "437:\tlearn: -0.4727149\ttotal: 36.6s\tremaining: 46.9s\n",
      "438:\tlearn: -0.4720053\ttotal: 36.6s\tremaining: 46.8s\n",
      "439:\tlearn: -0.4711273\ttotal: 36.7s\tremaining: 46.7s\n",
      "440:\tlearn: -0.4701588\ttotal: 36.8s\tremaining: 46.7s\n",
      "441:\tlearn: -0.4694494\ttotal: 36.9s\tremaining: 46.6s\n",
      "442:\tlearn: -0.4678881\ttotal: 37s\tremaining: 46.5s\n",
      "443:\tlearn: -0.4663847\ttotal: 37.1s\tremaining: 46.4s\n",
      "444:\tlearn: -0.4654991\ttotal: 37.2s\tremaining: 46.3s\n",
      "445:\tlearn: -0.4650899\ttotal: 37.2s\tremaining: 46.2s\n",
      "446:\tlearn: -0.4645682\ttotal: 37.3s\tremaining: 46.1s\n",
      "447:\tlearn: -0.4635953\ttotal: 37.4s\tremaining: 46.1s\n",
      "448:\tlearn: -0.4619969\ttotal: 37.5s\tremaining: 46s\n",
      "449:\tlearn: -0.4607995\ttotal: 37.6s\tremaining: 45.9s\n",
      "450:\tlearn: -0.4598763\ttotal: 37.6s\tremaining: 45.8s\n",
      "451:\tlearn: -0.4594454\ttotal: 37.7s\tremaining: 45.7s\n",
      "452:\tlearn: -0.4588369\ttotal: 37.8s\tremaining: 45.6s\n",
      "453:\tlearn: -0.4579556\ttotal: 37.9s\tremaining: 45.5s\n",
      "454:\tlearn: -0.4569849\ttotal: 37.9s\tremaining: 45.5s\n",
      "455:\tlearn: -0.4552861\ttotal: 38s\tremaining: 45.4s\n",
      "456:\tlearn: -0.4543791\ttotal: 38.1s\tremaining: 45.3s\n",
      "457:\tlearn: -0.4537829\ttotal: 38.2s\tremaining: 45.2s\n",
      "458:\tlearn: -0.4526237\ttotal: 38.3s\tremaining: 45.1s\n",
      "459:\tlearn: -0.4521420\ttotal: 38.4s\tremaining: 45s\n",
      "460:\tlearn: -0.4511711\ttotal: 38.4s\tremaining: 44.9s\n",
      "461:\tlearn: -0.4501718\ttotal: 38.5s\tremaining: 44.9s\n",
      "462:\tlearn: -0.4494476\ttotal: 38.6s\tremaining: 44.8s\n",
      "463:\tlearn: -0.4481763\ttotal: 38.7s\tremaining: 44.7s\n",
      "464:\tlearn: -0.4472101\ttotal: 38.8s\tremaining: 44.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "465:\tlearn: -0.4461854\ttotal: 38.9s\tremaining: 44.5s\n",
      "466:\tlearn: -0.4454733\ttotal: 38.9s\tremaining: 44.4s\n",
      "467:\tlearn: -0.4441195\ttotal: 39s\tremaining: 44.4s\n",
      "468:\tlearn: -0.4429415\ttotal: 39.1s\tremaining: 44.3s\n",
      "469:\tlearn: -0.4419509\ttotal: 39.2s\tremaining: 44.2s\n",
      "470:\tlearn: -0.4412139\ttotal: 39.3s\tremaining: 44.1s\n",
      "471:\tlearn: -0.4403568\ttotal: 39.4s\tremaining: 44s\n",
      "472:\tlearn: -0.4390677\ttotal: 39.4s\tremaining: 44s\n",
      "473:\tlearn: -0.4386787\ttotal: 39.5s\tremaining: 43.9s\n",
      "474:\tlearn: -0.4379790\ttotal: 39.6s\tremaining: 43.8s\n",
      "475:\tlearn: -0.4373307\ttotal: 39.7s\tremaining: 43.7s\n",
      "476:\tlearn: -0.4368731\ttotal: 39.7s\tremaining: 43.6s\n",
      "477:\tlearn: -0.4356652\ttotal: 39.8s\tremaining: 43.5s\n",
      "478:\tlearn: -0.4343828\ttotal: 39.9s\tremaining: 43.4s\n",
      "479:\tlearn: -0.4334422\ttotal: 40s\tremaining: 43.3s\n",
      "480:\tlearn: -0.4322428\ttotal: 40.1s\tremaining: 43.3s\n",
      "481:\tlearn: -0.4317275\ttotal: 40.2s\tremaining: 43.2s\n",
      "482:\tlearn: -0.4312098\ttotal: 40.2s\tremaining: 43.1s\n",
      "483:\tlearn: -0.4306125\ttotal: 40.3s\tremaining: 43s\n",
      "484:\tlearn: -0.4301578\ttotal: 40.4s\tremaining: 42.9s\n",
      "485:\tlearn: -0.4293507\ttotal: 40.5s\tremaining: 42.8s\n",
      "486:\tlearn: -0.4278121\ttotal: 40.6s\tremaining: 42.7s\n",
      "487:\tlearn: -0.4267679\ttotal: 40.6s\tremaining: 42.6s\n",
      "488:\tlearn: -0.4255064\ttotal: 40.7s\tremaining: 42.6s\n",
      "489:\tlearn: -0.4246849\ttotal: 40.8s\tremaining: 42.5s\n",
      "490:\tlearn: -0.4240353\ttotal: 40.9s\tremaining: 42.4s\n",
      "491:\tlearn: -0.4234723\ttotal: 41s\tremaining: 42.3s\n",
      "492:\tlearn: -0.4223737\ttotal: 41.1s\tremaining: 42.2s\n",
      "493:\tlearn: -0.4214866\ttotal: 41.1s\tremaining: 42.1s\n",
      "494:\tlearn: -0.4206633\ttotal: 41.2s\tremaining: 42s\n",
      "495:\tlearn: -0.4203388\ttotal: 41.3s\tremaining: 42s\n",
      "496:\tlearn: -0.4196491\ttotal: 41.4s\tremaining: 41.9s\n",
      "497:\tlearn: -0.4182010\ttotal: 41.5s\tremaining: 41.8s\n",
      "498:\tlearn: -0.4165908\ttotal: 41.6s\tremaining: 41.7s\n",
      "499:\tlearn: -0.4153632\ttotal: 41.6s\tremaining: 41.6s\n",
      "500:\tlearn: -0.4147608\ttotal: 41.7s\tremaining: 41.5s\n",
      "501:\tlearn: -0.4142138\ttotal: 41.8s\tremaining: 41.4s\n",
      "502:\tlearn: -0.4136578\ttotal: 41.9s\tremaining: 41.4s\n",
      "503:\tlearn: -0.4129152\ttotal: 41.9s\tremaining: 41.3s\n",
      "504:\tlearn: -0.4118394\ttotal: 42s\tremaining: 41.2s\n",
      "505:\tlearn: -0.4108068\ttotal: 42.1s\tremaining: 41.1s\n",
      "506:\tlearn: -0.4101248\ttotal: 42.2s\tremaining: 41s\n",
      "507:\tlearn: -0.4094356\ttotal: 42.3s\tremaining: 40.9s\n",
      "508:\tlearn: -0.4084408\ttotal: 42.3s\tremaining: 40.8s\n",
      "509:\tlearn: -0.4077973\ttotal: 42.4s\tremaining: 40.8s\n",
      "510:\tlearn: -0.4071062\ttotal: 42.5s\tremaining: 40.7s\n",
      "511:\tlearn: -0.4062404\ttotal: 42.6s\tremaining: 40.6s\n",
      "512:\tlearn: -0.4051868\ttotal: 42.7s\tremaining: 40.5s\n",
      "513:\tlearn: -0.4046866\ttotal: 42.7s\tremaining: 40.4s\n",
      "514:\tlearn: -0.4037850\ttotal: 42.8s\tremaining: 40.3s\n",
      "515:\tlearn: -0.4034443\ttotal: 42.9s\tremaining: 40.2s\n",
      "516:\tlearn: -0.4028277\ttotal: 43s\tremaining: 40.2s\n",
      "517:\tlearn: -0.4020658\ttotal: 43.1s\tremaining: 40.1s\n",
      "518:\tlearn: -0.4011356\ttotal: 43.1s\tremaining: 40s\n",
      "519:\tlearn: -0.4006586\ttotal: 43.2s\tremaining: 39.9s\n",
      "520:\tlearn: -0.3998529\ttotal: 43.3s\tremaining: 39.8s\n",
      "521:\tlearn: -0.3980624\ttotal: 43.4s\tremaining: 39.7s\n",
      "522:\tlearn: -0.3974858\ttotal: 43.5s\tremaining: 39.6s\n",
      "523:\tlearn: -0.3960090\ttotal: 43.6s\tremaining: 39.6s\n",
      "524:\tlearn: -0.3955301\ttotal: 43.6s\tremaining: 39.5s\n",
      "525:\tlearn: -0.3945516\ttotal: 43.7s\tremaining: 39.4s\n",
      "526:\tlearn: -0.3941116\ttotal: 43.8s\tremaining: 39.3s\n",
      "527:\tlearn: -0.3937484\ttotal: 43.9s\tremaining: 39.2s\n",
      "528:\tlearn: -0.3931028\ttotal: 43.9s\tremaining: 39.1s\n",
      "529:\tlearn: -0.3928433\ttotal: 44s\tremaining: 39s\n",
      "530:\tlearn: -0.3918079\ttotal: 44.1s\tremaining: 38.9s\n",
      "531:\tlearn: -0.3904807\ttotal: 44.2s\tremaining: 38.9s\n",
      "532:\tlearn: -0.3895614\ttotal: 44.3s\tremaining: 38.8s\n",
      "533:\tlearn: -0.3891338\ttotal: 44.4s\tremaining: 38.7s\n",
      "534:\tlearn: -0.3880591\ttotal: 44.4s\tremaining: 38.6s\n",
      "535:\tlearn: -0.3877419\ttotal: 44.5s\tremaining: 38.5s\n",
      "536:\tlearn: -0.3871168\ttotal: 44.6s\tremaining: 38.4s\n",
      "537:\tlearn: -0.3863335\ttotal: 44.7s\tremaining: 38.4s\n",
      "538:\tlearn: -0.3848502\ttotal: 44.8s\tremaining: 38.3s\n",
      "539:\tlearn: -0.3837351\ttotal: 44.9s\tremaining: 38.2s\n",
      "540:\tlearn: -0.3833717\ttotal: 44.9s\tremaining: 38.1s\n",
      "541:\tlearn: -0.3826047\ttotal: 45s\tremaining: 38s\n",
      "542:\tlearn: -0.3818563\ttotal: 45.1s\tremaining: 38s\n",
      "543:\tlearn: -0.3813490\ttotal: 45.2s\tremaining: 37.9s\n",
      "544:\tlearn: -0.3807715\ttotal: 45.3s\tremaining: 37.8s\n",
      "545:\tlearn: -0.3801966\ttotal: 45.3s\tremaining: 37.7s\n",
      "546:\tlearn: -0.3793768\ttotal: 45.4s\tremaining: 37.6s\n",
      "547:\tlearn: -0.3789864\ttotal: 45.5s\tremaining: 37.5s\n",
      "548:\tlearn: -0.3785588\ttotal: 45.6s\tremaining: 37.4s\n",
      "549:\tlearn: -0.3777711\ttotal: 45.6s\tremaining: 37.3s\n",
      "550:\tlearn: -0.3770705\ttotal: 45.7s\tremaining: 37.3s\n",
      "551:\tlearn: -0.3758906\ttotal: 45.8s\tremaining: 37.2s\n",
      "552:\tlearn: -0.3755750\ttotal: 45.9s\tremaining: 37.1s\n",
      "553:\tlearn: -0.3749710\ttotal: 46s\tremaining: 37s\n",
      "554:\tlearn: -0.3742758\ttotal: 46.1s\tremaining: 36.9s\n",
      "555:\tlearn: -0.3734043\ttotal: 46.1s\tremaining: 36.8s\n",
      "556:\tlearn: -0.3721381\ttotal: 46.2s\tremaining: 36.8s\n",
      "557:\tlearn: -0.3717148\ttotal: 46.3s\tremaining: 36.7s\n",
      "558:\tlearn: -0.3709876\ttotal: 46.4s\tremaining: 36.6s\n",
      "559:\tlearn: -0.3706634\ttotal: 46.5s\tremaining: 36.5s\n",
      "560:\tlearn: -0.3696516\ttotal: 46.6s\tremaining: 36.4s\n",
      "561:\tlearn: -0.3690211\ttotal: 46.6s\tremaining: 36.4s\n",
      "562:\tlearn: -0.3684535\ttotal: 46.7s\tremaining: 36.3s\n",
      "563:\tlearn: -0.3679132\ttotal: 46.8s\tremaining: 36.2s\n",
      "564:\tlearn: -0.3676164\ttotal: 46.9s\tremaining: 36.1s\n",
      "565:\tlearn: -0.3666483\ttotal: 47s\tremaining: 36s\n",
      "566:\tlearn: -0.3659956\ttotal: 47s\tremaining: 35.9s\n",
      "567:\tlearn: -0.3652867\ttotal: 47.1s\tremaining: 35.8s\n",
      "568:\tlearn: -0.3647882\ttotal: 47.2s\tremaining: 35.8s\n",
      "569:\tlearn: -0.3644252\ttotal: 47.3s\tremaining: 35.7s\n",
      "570:\tlearn: -0.3635468\ttotal: 47.4s\tremaining: 35.6s\n",
      "571:\tlearn: -0.3630790\ttotal: 47.5s\tremaining: 35.5s\n",
      "572:\tlearn: -0.3624591\ttotal: 47.5s\tremaining: 35.4s\n",
      "573:\tlearn: -0.3620845\ttotal: 47.6s\tremaining: 35.3s\n",
      "574:\tlearn: -0.3610613\ttotal: 47.7s\tremaining: 35.2s\n",
      "575:\tlearn: -0.3603454\ttotal: 47.8s\tremaining: 35.2s\n",
      "576:\tlearn: -0.3598218\ttotal: 47.9s\tremaining: 35.1s\n",
      "577:\tlearn: -0.3589502\ttotal: 47.9s\tremaining: 35s\n",
      "578:\tlearn: -0.3581682\ttotal: 48s\tremaining: 34.9s\n",
      "579:\tlearn: -0.3577036\ttotal: 48.1s\tremaining: 34.8s\n",
      "580:\tlearn: -0.3570014\ttotal: 48.2s\tremaining: 34.7s\n",
      "581:\tlearn: -0.3562019\ttotal: 48.2s\tremaining: 34.7s\n",
      "582:\tlearn: -0.3555459\ttotal: 48.3s\tremaining: 34.6s\n",
      "583:\tlearn: -0.3549219\ttotal: 48.4s\tremaining: 34.5s\n",
      "584:\tlearn: -0.3540582\ttotal: 48.5s\tremaining: 34.4s\n",
      "585:\tlearn: -0.3533197\ttotal: 48.6s\tremaining: 34.3s\n",
      "586:\tlearn: -0.3528087\ttotal: 48.6s\tremaining: 34.2s\n",
      "587:\tlearn: -0.3520831\ttotal: 48.7s\tremaining: 34.1s\n",
      "588:\tlearn: -0.3512966\ttotal: 48.8s\tremaining: 34.1s\n",
      "589:\tlearn: -0.3504743\ttotal: 48.9s\tremaining: 34s\n",
      "590:\tlearn: -0.3497302\ttotal: 49s\tremaining: 33.9s\n",
      "591:\tlearn: -0.3491303\ttotal: 49.1s\tremaining: 33.8s\n",
      "592:\tlearn: -0.3488359\ttotal: 49.1s\tremaining: 33.7s\n",
      "593:\tlearn: -0.3483364\ttotal: 49.2s\tremaining: 33.6s\n",
      "594:\tlearn: -0.3477806\ttotal: 49.3s\tremaining: 33.6s\n",
      "595:\tlearn: -0.3474954\ttotal: 49.4s\tremaining: 33.5s\n",
      "596:\tlearn: -0.3470533\ttotal: 49.5s\tremaining: 33.4s\n",
      "597:\tlearn: -0.3463195\ttotal: 49.5s\tremaining: 33.3s\n",
      "598:\tlearn: -0.3461415\ttotal: 49.6s\tremaining: 33.2s\n",
      "599:\tlearn: -0.3458013\ttotal: 49.7s\tremaining: 33.1s\n",
      "600:\tlearn: -0.3449561\ttotal: 49.8s\tremaining: 33s\n",
      "601:\tlearn: -0.3445388\ttotal: 49.8s\tremaining: 33s\n",
      "602:\tlearn: -0.3438442\ttotal: 49.9s\tremaining: 32.9s\n",
      "603:\tlearn: -0.3433418\ttotal: 50s\tremaining: 32.8s\n",
      "604:\tlearn: -0.3423457\ttotal: 50.1s\tremaining: 32.7s\n",
      "605:\tlearn: -0.3418896\ttotal: 50.2s\tremaining: 32.6s\n",
      "606:\tlearn: -0.3413521\ttotal: 50.3s\tremaining: 32.5s\n",
      "607:\tlearn: -0.3407032\ttotal: 50.3s\tremaining: 32.5s\n",
      "608:\tlearn: -0.3401711\ttotal: 50.4s\tremaining: 32.4s\n",
      "609:\tlearn: -0.3394844\ttotal: 50.5s\tremaining: 32.3s\n",
      "610:\tlearn: -0.3390119\ttotal: 50.6s\tremaining: 32.2s\n",
      "611:\tlearn: -0.3381592\ttotal: 50.7s\tremaining: 32.1s\n",
      "612:\tlearn: -0.3375214\ttotal: 50.8s\tremaining: 32s\n",
      "613:\tlearn: -0.3368865\ttotal: 50.8s\tremaining: 32s\n",
      "614:\tlearn: -0.3365120\ttotal: 50.9s\tremaining: 31.9s\n",
      "615:\tlearn: -0.3361355\ttotal: 51s\tremaining: 31.8s\n",
      "616:\tlearn: -0.3355273\ttotal: 51.1s\tremaining: 31.7s\n",
      "617:\tlearn: -0.3345293\ttotal: 51.2s\tremaining: 31.6s\n",
      "618:\tlearn: -0.3340399\ttotal: 51.2s\tremaining: 31.5s\n",
      "619:\tlearn: -0.3336390\ttotal: 51.3s\tremaining: 31.4s\n",
      "620:\tlearn: -0.3331133\ttotal: 51.4s\tremaining: 31.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "621:\tlearn: -0.3328437\ttotal: 51.5s\tremaining: 31.3s\n",
      "622:\tlearn: -0.3322767\ttotal: 51.5s\tremaining: 31.2s\n",
      "623:\tlearn: -0.3319827\ttotal: 51.6s\tremaining: 31.1s\n",
      "624:\tlearn: -0.3313082\ttotal: 51.7s\tremaining: 31s\n",
      "625:\tlearn: -0.3303172\ttotal: 51.8s\tremaining: 30.9s\n",
      "626:\tlearn: -0.3296787\ttotal: 51.9s\tremaining: 30.9s\n",
      "627:\tlearn: -0.3293320\ttotal: 51.9s\tremaining: 30.8s\n",
      "628:\tlearn: -0.3286808\ttotal: 52s\tremaining: 30.7s\n",
      "629:\tlearn: -0.3279204\ttotal: 52.1s\tremaining: 30.6s\n",
      "630:\tlearn: -0.3276702\ttotal: 52.2s\tremaining: 30.5s\n",
      "631:\tlearn: -0.3273713\ttotal: 52.2s\tremaining: 30.4s\n",
      "632:\tlearn: -0.3267292\ttotal: 52.3s\tremaining: 30.3s\n",
      "633:\tlearn: -0.3264252\ttotal: 52.4s\tremaining: 30.3s\n",
      "634:\tlearn: -0.3262042\ttotal: 52.5s\tremaining: 30.2s\n",
      "635:\tlearn: -0.3256284\ttotal: 52.6s\tremaining: 30.1s\n",
      "636:\tlearn: -0.3252646\ttotal: 52.6s\tremaining: 30s\n",
      "637:\tlearn: -0.3249139\ttotal: 52.7s\tremaining: 29.9s\n",
      "638:\tlearn: -0.3243946\ttotal: 52.8s\tremaining: 29.8s\n",
      "639:\tlearn: -0.3239507\ttotal: 52.9s\tremaining: 29.7s\n",
      "640:\tlearn: -0.3231984\ttotal: 53s\tremaining: 29.7s\n",
      "641:\tlearn: -0.3227061\ttotal: 53s\tremaining: 29.6s\n",
      "642:\tlearn: -0.3221774\ttotal: 53.1s\tremaining: 29.5s\n",
      "643:\tlearn: -0.3217871\ttotal: 53.2s\tremaining: 29.4s\n",
      "644:\tlearn: -0.3214793\ttotal: 53.3s\tremaining: 29.3s\n",
      "645:\tlearn: -0.3207186\ttotal: 53.4s\tremaining: 29.2s\n",
      "646:\tlearn: -0.3205046\ttotal: 53.4s\tremaining: 29.2s\n",
      "647:\tlearn: -0.3202324\ttotal: 53.5s\tremaining: 29.1s\n",
      "648:\tlearn: -0.3197668\ttotal: 53.6s\tremaining: 29s\n",
      "649:\tlearn: -0.3195040\ttotal: 53.7s\tremaining: 28.9s\n",
      "650:\tlearn: -0.3190196\ttotal: 53.7s\tremaining: 28.8s\n",
      "651:\tlearn: -0.3186358\ttotal: 53.8s\tremaining: 28.7s\n",
      "652:\tlearn: -0.3180266\ttotal: 53.9s\tremaining: 28.6s\n",
      "653:\tlearn: -0.3176105\ttotal: 54s\tremaining: 28.6s\n",
      "654:\tlearn: -0.3174389\ttotal: 54s\tremaining: 28.5s\n",
      "655:\tlearn: -0.3171414\ttotal: 54.1s\tremaining: 28.4s\n",
      "656:\tlearn: -0.3167990\ttotal: 54.2s\tremaining: 28.3s\n",
      "657:\tlearn: -0.3163425\ttotal: 54.3s\tremaining: 28.2s\n",
      "658:\tlearn: -0.3157128\ttotal: 54.4s\tremaining: 28.1s\n",
      "659:\tlearn: -0.3150773\ttotal: 54.4s\tremaining: 28s\n",
      "660:\tlearn: -0.3142326\ttotal: 54.5s\tremaining: 28s\n",
      "661:\tlearn: -0.3139068\ttotal: 54.6s\tremaining: 27.9s\n",
      "662:\tlearn: -0.3133397\ttotal: 54.7s\tremaining: 27.8s\n",
      "663:\tlearn: -0.3129604\ttotal: 54.8s\tremaining: 27.7s\n",
      "664:\tlearn: -0.3126362\ttotal: 54.9s\tremaining: 27.6s\n",
      "665:\tlearn: -0.3122891\ttotal: 54.9s\tremaining: 27.5s\n",
      "666:\tlearn: -0.3116839\ttotal: 55s\tremaining: 27.5s\n",
      "667:\tlearn: -0.3109755\ttotal: 55.1s\tremaining: 27.4s\n",
      "668:\tlearn: -0.3104364\ttotal: 55.2s\tremaining: 27.3s\n",
      "669:\tlearn: -0.3099288\ttotal: 55.3s\tremaining: 27.2s\n",
      "670:\tlearn: -0.3095393\ttotal: 55.3s\tremaining: 27.1s\n",
      "671:\tlearn: -0.3090029\ttotal: 55.4s\tremaining: 27s\n",
      "672:\tlearn: -0.3086638\ttotal: 55.5s\tremaining: 27s\n",
      "673:\tlearn: -0.3083875\ttotal: 55.6s\tremaining: 26.9s\n",
      "674:\tlearn: -0.3077543\ttotal: 55.6s\tremaining: 26.8s\n",
      "675:\tlearn: -0.3073716\ttotal: 55.7s\tremaining: 26.7s\n",
      "676:\tlearn: -0.3066323\ttotal: 55.8s\tremaining: 26.6s\n",
      "677:\tlearn: -0.3057860\ttotal: 55.9s\tremaining: 26.5s\n",
      "678:\tlearn: -0.3051902\ttotal: 56s\tremaining: 26.5s\n",
      "679:\tlearn: -0.3045555\ttotal: 56.1s\tremaining: 26.4s\n",
      "680:\tlearn: -0.3041734\ttotal: 56.1s\tremaining: 26.3s\n",
      "681:\tlearn: -0.3038253\ttotal: 56.2s\tremaining: 26.2s\n",
      "682:\tlearn: -0.3033712\ttotal: 56.3s\tremaining: 26.1s\n",
      "683:\tlearn: -0.3028174\ttotal: 56.4s\tremaining: 26s\n",
      "684:\tlearn: -0.3023052\ttotal: 56.5s\tremaining: 26s\n",
      "685:\tlearn: -0.3016003\ttotal: 56.6s\tremaining: 25.9s\n",
      "686:\tlearn: -0.3011897\ttotal: 56.6s\tremaining: 25.8s\n",
      "687:\tlearn: -0.3004835\ttotal: 56.7s\tremaining: 25.7s\n",
      "688:\tlearn: -0.3000129\ttotal: 56.8s\tremaining: 25.6s\n",
      "689:\tlearn: -0.2994754\ttotal: 56.9s\tremaining: 25.6s\n",
      "690:\tlearn: -0.2988955\ttotal: 57s\tremaining: 25.5s\n",
      "691:\tlearn: -0.2985297\ttotal: 57s\tremaining: 25.4s\n",
      "692:\tlearn: -0.2980298\ttotal: 57.1s\tremaining: 25.3s\n",
      "693:\tlearn: -0.2978410\ttotal: 57.2s\tremaining: 25.2s\n",
      "694:\tlearn: -0.2974689\ttotal: 57.3s\tremaining: 25.1s\n",
      "695:\tlearn: -0.2967105\ttotal: 57.3s\tremaining: 25s\n",
      "696:\tlearn: -0.2962942\ttotal: 57.4s\tremaining: 25s\n",
      "697:\tlearn: -0.2958956\ttotal: 57.5s\tremaining: 24.9s\n",
      "698:\tlearn: -0.2955657\ttotal: 57.6s\tremaining: 24.8s\n",
      "699:\tlearn: -0.2950015\ttotal: 57.7s\tremaining: 24.7s\n",
      "700:\tlearn: -0.2947134\ttotal: 57.7s\tremaining: 24.6s\n",
      "701:\tlearn: -0.2944953\ttotal: 57.8s\tremaining: 24.5s\n",
      "702:\tlearn: -0.2939623\ttotal: 57.9s\tremaining: 24.5s\n",
      "703:\tlearn: -0.2936397\ttotal: 58s\tremaining: 24.4s\n",
      "704:\tlearn: -0.2933060\ttotal: 58s\tremaining: 24.3s\n",
      "705:\tlearn: -0.2925481\ttotal: 58.1s\tremaining: 24.2s\n",
      "706:\tlearn: -0.2921511\ttotal: 58.2s\tremaining: 24.1s\n",
      "707:\tlearn: -0.2915983\ttotal: 58.3s\tremaining: 24s\n",
      "708:\tlearn: -0.2912752\ttotal: 58.4s\tremaining: 24s\n",
      "709:\tlearn: -0.2907358\ttotal: 58.5s\tremaining: 23.9s\n",
      "710:\tlearn: -0.2901884\ttotal: 58.5s\tremaining: 23.8s\n",
      "711:\tlearn: -0.2900126\ttotal: 58.6s\tremaining: 23.7s\n",
      "712:\tlearn: -0.2895840\ttotal: 58.7s\tremaining: 23.6s\n",
      "713:\tlearn: -0.2893293\ttotal: 58.8s\tremaining: 23.5s\n",
      "714:\tlearn: -0.2891997\ttotal: 58.8s\tremaining: 23.5s\n",
      "715:\tlearn: -0.2885857\ttotal: 58.9s\tremaining: 23.4s\n",
      "716:\tlearn: -0.2882333\ttotal: 59s\tremaining: 23.3s\n",
      "717:\tlearn: -0.2878529\ttotal: 59.1s\tremaining: 23.2s\n",
      "718:\tlearn: -0.2871852\ttotal: 59.2s\tremaining: 23.1s\n",
      "719:\tlearn: -0.2869510\ttotal: 59.2s\tremaining: 23s\n",
      "720:\tlearn: -0.2862143\ttotal: 59.3s\tremaining: 23s\n",
      "721:\tlearn: -0.2858803\ttotal: 59.4s\tremaining: 22.9s\n",
      "722:\tlearn: -0.2855760\ttotal: 59.5s\tremaining: 22.8s\n",
      "723:\tlearn: -0.2847979\ttotal: 59.6s\tremaining: 22.7s\n",
      "724:\tlearn: -0.2846163\ttotal: 59.7s\tremaining: 22.6s\n",
      "725:\tlearn: -0.2842519\ttotal: 59.8s\tremaining: 22.6s\n",
      "726:\tlearn: -0.2839473\ttotal: 59.8s\tremaining: 22.5s\n",
      "727:\tlearn: -0.2834651\ttotal: 59.9s\tremaining: 22.4s\n",
      "728:\tlearn: -0.2829853\ttotal: 60s\tremaining: 22.3s\n",
      "729:\tlearn: -0.2823654\ttotal: 1m\tremaining: 22.2s\n",
      "730:\tlearn: -0.2818724\ttotal: 1m\tremaining: 22.1s\n",
      "731:\tlearn: -0.2811360\ttotal: 1m\tremaining: 22.1s\n",
      "732:\tlearn: -0.2808473\ttotal: 1m\tremaining: 22s\n",
      "733:\tlearn: -0.2805685\ttotal: 1m\tremaining: 21.9s\n",
      "734:\tlearn: -0.2802392\ttotal: 1m\tremaining: 21.8s\n",
      "735:\tlearn: -0.2799512\ttotal: 1m\tremaining: 21.7s\n",
      "736:\tlearn: -0.2795428\ttotal: 1m\tremaining: 21.6s\n",
      "737:\tlearn: -0.2791454\ttotal: 1m\tremaining: 21.6s\n",
      "738:\tlearn: -0.2786878\ttotal: 1m\tremaining: 21.5s\n",
      "739:\tlearn: -0.2781868\ttotal: 1m\tremaining: 21.4s\n",
      "740:\tlearn: -0.2775931\ttotal: 1m\tremaining: 21.3s\n",
      "741:\tlearn: -0.2773309\ttotal: 1m 1s\tremaining: 21.2s\n",
      "742:\tlearn: -0.2770568\ttotal: 1m 1s\tremaining: 21.1s\n",
      "743:\tlearn: -0.2763881\ttotal: 1m 1s\tremaining: 21.1s\n",
      "744:\tlearn: -0.2759108\ttotal: 1m 1s\tremaining: 21s\n",
      "745:\tlearn: -0.2755942\ttotal: 1m 1s\tremaining: 20.9s\n",
      "746:\tlearn: -0.2750398\ttotal: 1m 1s\tremaining: 20.8s\n",
      "747:\tlearn: -0.2745698\ttotal: 1m 1s\tremaining: 20.7s\n",
      "748:\tlearn: -0.2742113\ttotal: 1m 1s\tremaining: 20.6s\n",
      "749:\tlearn: -0.2735816\ttotal: 1m 1s\tremaining: 20.6s\n",
      "750:\tlearn: -0.2727879\ttotal: 1m 1s\tremaining: 20.5s\n",
      "751:\tlearn: -0.2722223\ttotal: 1m 1s\tremaining: 20.4s\n",
      "752:\tlearn: -0.2720638\ttotal: 1m 1s\tremaining: 20.3s\n",
      "753:\tlearn: -0.2716108\ttotal: 1m 2s\tremaining: 20.2s\n",
      "754:\tlearn: -0.2713475\ttotal: 1m 2s\tremaining: 20.2s\n",
      "755:\tlearn: -0.2710581\ttotal: 1m 2s\tremaining: 20.1s\n",
      "756:\tlearn: -0.2704748\ttotal: 1m 2s\tremaining: 20s\n",
      "757:\tlearn: -0.2701300\ttotal: 1m 2s\tremaining: 19.9s\n",
      "758:\tlearn: -0.2696521\ttotal: 1m 2s\tremaining: 19.8s\n",
      "759:\tlearn: -0.2695438\ttotal: 1m 2s\tremaining: 19.7s\n",
      "760:\tlearn: -0.2692743\ttotal: 1m 2s\tremaining: 19.6s\n",
      "761:\tlearn: -0.2690075\ttotal: 1m 2s\tremaining: 19.6s\n",
      "762:\tlearn: -0.2686931\ttotal: 1m 2s\tremaining: 19.5s\n",
      "763:\tlearn: -0.2683324\ttotal: 1m 2s\tremaining: 19.4s\n",
      "764:\tlearn: -0.2678266\ttotal: 1m 2s\tremaining: 19.3s\n",
      "765:\tlearn: -0.2675805\ttotal: 1m 2s\tremaining: 19.2s\n",
      "766:\tlearn: -0.2673365\ttotal: 1m 3s\tremaining: 19.1s\n",
      "767:\tlearn: -0.2668940\ttotal: 1m 3s\tremaining: 19.1s\n",
      "768:\tlearn: -0.2664809\ttotal: 1m 3s\tremaining: 19s\n",
      "769:\tlearn: -0.2662164\ttotal: 1m 3s\tremaining: 18.9s\n",
      "770:\tlearn: -0.2659092\ttotal: 1m 3s\tremaining: 18.8s\n",
      "771:\tlearn: -0.2651483\ttotal: 1m 3s\tremaining: 18.7s\n",
      "772:\tlearn: -0.2645155\ttotal: 1m 3s\tremaining: 18.6s\n",
      "773:\tlearn: -0.2640742\ttotal: 1m 3s\tremaining: 18.6s\n",
      "774:\tlearn: -0.2638047\ttotal: 1m 3s\tremaining: 18.5s\n",
      "775:\tlearn: -0.2635792\ttotal: 1m 3s\tremaining: 18.4s\n",
      "776:\tlearn: -0.2629452\ttotal: 1m 3s\tremaining: 18.3s\n",
      "777:\tlearn: -0.2626615\ttotal: 1m 3s\tremaining: 18.2s\n",
      "778:\tlearn: -0.2619856\ttotal: 1m 3s\tremaining: 18.2s\n",
      "779:\tlearn: -0.2615123\ttotal: 1m 4s\tremaining: 18.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "780:\tlearn: -0.2609282\ttotal: 1m 4s\tremaining: 18s\n",
      "781:\tlearn: -0.2607214\ttotal: 1m 4s\tremaining: 17.9s\n",
      "782:\tlearn: -0.2604466\ttotal: 1m 4s\tremaining: 17.8s\n",
      "783:\tlearn: -0.2600405\ttotal: 1m 4s\tremaining: 17.7s\n",
      "784:\tlearn: -0.2593663\ttotal: 1m 4s\tremaining: 17.7s\n",
      "785:\tlearn: -0.2589410\ttotal: 1m 4s\tremaining: 17.6s\n",
      "786:\tlearn: -0.2582655\ttotal: 1m 4s\tremaining: 17.5s\n",
      "787:\tlearn: -0.2580678\ttotal: 1m 4s\tremaining: 17.4s\n",
      "788:\tlearn: -0.2579172\ttotal: 1m 4s\tremaining: 17.3s\n",
      "789:\tlearn: -0.2573962\ttotal: 1m 4s\tremaining: 17.3s\n",
      "790:\tlearn: -0.2572190\ttotal: 1m 4s\tremaining: 17.2s\n",
      "791:\tlearn: -0.2567047\ttotal: 1m 5s\tremaining: 17.1s\n",
      "792:\tlearn: -0.2563477\ttotal: 1m 5s\tremaining: 17s\n",
      "793:\tlearn: -0.2559804\ttotal: 1m 5s\tremaining: 16.9s\n",
      "794:\tlearn: -0.2554635\ttotal: 1m 5s\tremaining: 16.8s\n",
      "795:\tlearn: -0.2551837\ttotal: 1m 5s\tremaining: 16.8s\n",
      "796:\tlearn: -0.2549520\ttotal: 1m 5s\tremaining: 16.7s\n",
      "797:\tlearn: -0.2545993\ttotal: 1m 5s\tremaining: 16.6s\n",
      "798:\tlearn: -0.2543992\ttotal: 1m 5s\tremaining: 16.5s\n",
      "799:\tlearn: -0.2540457\ttotal: 1m 5s\tremaining: 16.4s\n",
      "800:\tlearn: -0.2536779\ttotal: 1m 5s\tremaining: 16.3s\n",
      "801:\tlearn: -0.2529454\ttotal: 1m 5s\tremaining: 16.3s\n",
      "802:\tlearn: -0.2525899\ttotal: 1m 5s\tremaining: 16.2s\n",
      "803:\tlearn: -0.2519509\ttotal: 1m 6s\tremaining: 16.1s\n",
      "804:\tlearn: -0.2515720\ttotal: 1m 6s\tremaining: 16s\n",
      "805:\tlearn: -0.2512541\ttotal: 1m 6s\tremaining: 15.9s\n",
      "806:\tlearn: -0.2509038\ttotal: 1m 6s\tremaining: 15.8s\n",
      "807:\tlearn: -0.2506801\ttotal: 1m 6s\tremaining: 15.8s\n",
      "808:\tlearn: -0.2502673\ttotal: 1m 6s\tremaining: 15.7s\n",
      "809:\tlearn: -0.2496975\ttotal: 1m 6s\tremaining: 15.6s\n",
      "810:\tlearn: -0.2490203\ttotal: 1m 6s\tremaining: 15.5s\n",
      "811:\tlearn: -0.2487068\ttotal: 1m 6s\tremaining: 15.4s\n",
      "812:\tlearn: -0.2481420\ttotal: 1m 6s\tremaining: 15.4s\n",
      "813:\tlearn: -0.2480238\ttotal: 1m 6s\tremaining: 15.3s\n",
      "814:\tlearn: -0.2477431\ttotal: 1m 6s\tremaining: 15.2s\n",
      "815:\tlearn: -0.2475028\ttotal: 1m 7s\tremaining: 15.1s\n",
      "816:\tlearn: -0.2472667\ttotal: 1m 7s\tremaining: 15s\n",
      "817:\tlearn: -0.2469574\ttotal: 1m 7s\tremaining: 14.9s\n",
      "818:\tlearn: -0.2466186\ttotal: 1m 7s\tremaining: 14.9s\n",
      "819:\tlearn: -0.2463695\ttotal: 1m 7s\tremaining: 14.8s\n",
      "820:\tlearn: -0.2460908\ttotal: 1m 7s\tremaining: 14.7s\n",
      "821:\tlearn: -0.2459989\ttotal: 1m 7s\tremaining: 14.6s\n",
      "822:\tlearn: -0.2456897\ttotal: 1m 7s\tremaining: 14.5s\n",
      "823:\tlearn: -0.2451310\ttotal: 1m 7s\tremaining: 14.4s\n",
      "824:\tlearn: -0.2447426\ttotal: 1m 7s\tremaining: 14.4s\n",
      "825:\tlearn: -0.2444451\ttotal: 1m 7s\tremaining: 14.3s\n",
      "826:\tlearn: -0.2442248\ttotal: 1m 7s\tremaining: 14.2s\n",
      "827:\tlearn: -0.2441269\ttotal: 1m 7s\tremaining: 14.1s\n",
      "828:\tlearn: -0.2439674\ttotal: 1m 7s\tremaining: 14s\n",
      "829:\tlearn: -0.2431465\ttotal: 1m 8s\tremaining: 13.9s\n",
      "830:\tlearn: -0.2427751\ttotal: 1m 8s\tremaining: 13.9s\n",
      "831:\tlearn: -0.2425529\ttotal: 1m 8s\tremaining: 13.8s\n",
      "832:\tlearn: -0.2424006\ttotal: 1m 8s\tremaining: 13.7s\n",
      "833:\tlearn: -0.2418214\ttotal: 1m 8s\tremaining: 13.6s\n",
      "834:\tlearn: -0.2414510\ttotal: 1m 8s\tremaining: 13.5s\n",
      "835:\tlearn: -0.2413079\ttotal: 1m 8s\tremaining: 13.4s\n",
      "836:\tlearn: -0.2409207\ttotal: 1m 8s\tremaining: 13.4s\n",
      "837:\tlearn: -0.2404907\ttotal: 1m 8s\tremaining: 13.3s\n",
      "838:\tlearn: -0.2398965\ttotal: 1m 8s\tremaining: 13.2s\n",
      "839:\tlearn: -0.2393327\ttotal: 1m 8s\tremaining: 13.1s\n",
      "840:\tlearn: -0.2391123\ttotal: 1m 8s\tremaining: 13s\n",
      "841:\tlearn: -0.2388379\ttotal: 1m 9s\tremaining: 13s\n",
      "842:\tlearn: -0.2383014\ttotal: 1m 9s\tremaining: 12.9s\n",
      "843:\tlearn: -0.2376771\ttotal: 1m 9s\tremaining: 12.8s\n",
      "844:\tlearn: -0.2373590\ttotal: 1m 9s\tremaining: 12.7s\n",
      "845:\tlearn: -0.2372047\ttotal: 1m 9s\tremaining: 12.6s\n",
      "846:\tlearn: -0.2367865\ttotal: 1m 9s\tremaining: 12.5s\n",
      "847:\tlearn: -0.2362501\ttotal: 1m 9s\tremaining: 12.5s\n",
      "848:\tlearn: -0.2360401\ttotal: 1m 9s\tremaining: 12.4s\n",
      "849:\tlearn: -0.2354504\ttotal: 1m 9s\tremaining: 12.3s\n",
      "850:\tlearn: -0.2352574\ttotal: 1m 9s\tremaining: 12.2s\n",
      "851:\tlearn: -0.2350443\ttotal: 1m 9s\tremaining: 12.1s\n",
      "852:\tlearn: -0.2348232\ttotal: 1m 9s\tremaining: 12.1s\n",
      "853:\tlearn: -0.2346838\ttotal: 1m 10s\tremaining: 12s\n",
      "854:\tlearn: -0.2341255\ttotal: 1m 10s\tremaining: 11.9s\n",
      "855:\tlearn: -0.2336556\ttotal: 1m 10s\tremaining: 11.8s\n",
      "856:\tlearn: -0.2333630\ttotal: 1m 10s\tremaining: 11.7s\n",
      "857:\tlearn: -0.2330886\ttotal: 1m 10s\tremaining: 11.6s\n",
      "858:\tlearn: -0.2326165\ttotal: 1m 10s\tremaining: 11.6s\n",
      "859:\tlearn: -0.2324802\ttotal: 1m 10s\tremaining: 11.5s\n",
      "860:\tlearn: -0.2322313\ttotal: 1m 10s\tremaining: 11.4s\n",
      "861:\tlearn: -0.2320834\ttotal: 1m 10s\tremaining: 11.3s\n",
      "862:\tlearn: -0.2319061\ttotal: 1m 10s\tremaining: 11.2s\n",
      "863:\tlearn: -0.2315455\ttotal: 1m 10s\tremaining: 11.1s\n",
      "864:\tlearn: -0.2313826\ttotal: 1m 10s\tremaining: 11.1s\n",
      "865:\tlearn: -0.2312250\ttotal: 1m 10s\tremaining: 11s\n",
      "866:\tlearn: -0.2308472\ttotal: 1m 11s\tremaining: 10.9s\n",
      "867:\tlearn: -0.2306585\ttotal: 1m 11s\tremaining: 10.8s\n",
      "868:\tlearn: -0.2300395\ttotal: 1m 11s\tremaining: 10.7s\n",
      "869:\tlearn: -0.2296352\ttotal: 1m 11s\tremaining: 10.7s\n",
      "870:\tlearn: -0.2291410\ttotal: 1m 11s\tremaining: 10.6s\n",
      "871:\tlearn: -0.2290192\ttotal: 1m 11s\tremaining: 10.5s\n",
      "872:\tlearn: -0.2289248\ttotal: 1m 11s\tremaining: 10.4s\n",
      "873:\tlearn: -0.2285483\ttotal: 1m 11s\tremaining: 10.3s\n",
      "874:\tlearn: -0.2283897\ttotal: 1m 11s\tremaining: 10.2s\n",
      "875:\tlearn: -0.2278826\ttotal: 1m 11s\tremaining: 10.2s\n",
      "876:\tlearn: -0.2275344\ttotal: 1m 11s\tremaining: 10.1s\n",
      "877:\tlearn: -0.2272389\ttotal: 1m 11s\tremaining: 9.99s\n",
      "878:\tlearn: -0.2269254\ttotal: 1m 11s\tremaining: 9.91s\n",
      "879:\tlearn: -0.2267634\ttotal: 1m 12s\tremaining: 9.83s\n",
      "880:\tlearn: -0.2264628\ttotal: 1m 12s\tremaining: 9.74s\n",
      "881:\tlearn: -0.2262131\ttotal: 1m 12s\tremaining: 9.66s\n",
      "882:\tlearn: -0.2260162\ttotal: 1m 12s\tremaining: 9.58s\n",
      "883:\tlearn: -0.2256771\ttotal: 1m 12s\tremaining: 9.5s\n",
      "884:\tlearn: -0.2255306\ttotal: 1m 12s\tremaining: 9.41s\n",
      "885:\tlearn: -0.2253004\ttotal: 1m 12s\tremaining: 9.33s\n",
      "886:\tlearn: -0.2250343\ttotal: 1m 12s\tremaining: 9.25s\n",
      "887:\tlearn: -0.2246945\ttotal: 1m 12s\tremaining: 9.17s\n",
      "888:\tlearn: -0.2244000\ttotal: 1m 12s\tremaining: 9.09s\n",
      "889:\tlearn: -0.2241423\ttotal: 1m 12s\tremaining: 9s\n",
      "890:\tlearn: -0.2240067\ttotal: 1m 12s\tremaining: 8.92s\n",
      "891:\tlearn: -0.2238037\ttotal: 1m 12s\tremaining: 8.84s\n",
      "892:\tlearn: -0.2235169\ttotal: 1m 13s\tremaining: 8.76s\n",
      "893:\tlearn: -0.2233028\ttotal: 1m 13s\tremaining: 8.67s\n",
      "894:\tlearn: -0.2229863\ttotal: 1m 13s\tremaining: 8.59s\n",
      "895:\tlearn: -0.2223672\ttotal: 1m 13s\tremaining: 8.51s\n",
      "896:\tlearn: -0.2219288\ttotal: 1m 13s\tremaining: 8.43s\n",
      "897:\tlearn: -0.2216839\ttotal: 1m 13s\tremaining: 8.35s\n",
      "898:\tlearn: -0.2213717\ttotal: 1m 13s\tremaining: 8.26s\n",
      "899:\tlearn: -0.2209774\ttotal: 1m 13s\tremaining: 8.18s\n",
      "900:\tlearn: -0.2207070\ttotal: 1m 13s\tremaining: 8.1s\n",
      "901:\tlearn: -0.2203850\ttotal: 1m 13s\tremaining: 8.02s\n",
      "902:\tlearn: -0.2201652\ttotal: 1m 13s\tremaining: 7.94s\n",
      "903:\tlearn: -0.2198386\ttotal: 1m 13s\tremaining: 7.85s\n",
      "904:\tlearn: -0.2195148\ttotal: 1m 14s\tremaining: 7.77s\n",
      "905:\tlearn: -0.2192030\ttotal: 1m 14s\tremaining: 7.69s\n",
      "906:\tlearn: -0.2188439\ttotal: 1m 14s\tremaining: 7.61s\n",
      "907:\tlearn: -0.2186721\ttotal: 1m 14s\tremaining: 7.53s\n",
      "908:\tlearn: -0.2180981\ttotal: 1m 14s\tremaining: 7.45s\n",
      "909:\tlearn: -0.2178417\ttotal: 1m 14s\tremaining: 7.36s\n",
      "910:\tlearn: -0.2175928\ttotal: 1m 14s\tremaining: 7.28s\n",
      "911:\tlearn: -0.2172810\ttotal: 1m 14s\tremaining: 7.2s\n",
      "912:\tlearn: -0.2169551\ttotal: 1m 14s\tremaining: 7.12s\n",
      "913:\tlearn: -0.2166940\ttotal: 1m 14s\tremaining: 7.04s\n",
      "914:\tlearn: -0.2164965\ttotal: 1m 14s\tremaining: 6.95s\n",
      "915:\tlearn: -0.2159971\ttotal: 1m 14s\tremaining: 6.87s\n",
      "916:\tlearn: -0.2153604\ttotal: 1m 15s\tremaining: 6.79s\n",
      "917:\tlearn: -0.2149973\ttotal: 1m 15s\tremaining: 6.71s\n",
      "918:\tlearn: -0.2148512\ttotal: 1m 15s\tremaining: 6.63s\n",
      "919:\tlearn: -0.2146020\ttotal: 1m 15s\tremaining: 6.54s\n",
      "920:\tlearn: -0.2142001\ttotal: 1m 15s\tremaining: 6.46s\n",
      "921:\tlearn: -0.2139708\ttotal: 1m 15s\tremaining: 6.38s\n",
      "922:\tlearn: -0.2136208\ttotal: 1m 15s\tremaining: 6.3s\n",
      "923:\tlearn: -0.2134510\ttotal: 1m 15s\tremaining: 6.22s\n",
      "924:\tlearn: -0.2132290\ttotal: 1m 15s\tremaining: 6.13s\n",
      "925:\tlearn: -0.2130324\ttotal: 1m 15s\tremaining: 6.05s\n",
      "926:\tlearn: -0.2128748\ttotal: 1m 15s\tremaining: 5.97s\n",
      "927:\tlearn: -0.2123674\ttotal: 1m 15s\tremaining: 5.89s\n",
      "928:\tlearn: -0.2120495\ttotal: 1m 15s\tremaining: 5.8s\n",
      "929:\tlearn: -0.2117793\ttotal: 1m 16s\tremaining: 5.72s\n",
      "930:\tlearn: -0.2116383\ttotal: 1m 16s\tremaining: 5.64s\n",
      "931:\tlearn: -0.2113934\ttotal: 1m 16s\tremaining: 5.56s\n",
      "932:\tlearn: -0.2111693\ttotal: 1m 16s\tremaining: 5.48s\n",
      "933:\tlearn: -0.2108622\ttotal: 1m 16s\tremaining: 5.39s\n",
      "934:\tlearn: -0.2104588\ttotal: 1m 16s\tremaining: 5.31s\n",
      "935:\tlearn: -0.2100338\ttotal: 1m 16s\tremaining: 5.23s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "936:\tlearn: -0.2097812\ttotal: 1m 16s\tremaining: 5.15s\n",
      "937:\tlearn: -0.2094456\ttotal: 1m 16s\tremaining: 5.07s\n",
      "938:\tlearn: -0.2091962\ttotal: 1m 16s\tremaining: 4.99s\n",
      "939:\tlearn: -0.2089707\ttotal: 1m 16s\tremaining: 4.9s\n",
      "940:\tlearn: -0.2085733\ttotal: 1m 16s\tremaining: 4.82s\n",
      "941:\tlearn: -0.2079955\ttotal: 1m 17s\tremaining: 4.74s\n",
      "942:\tlearn: -0.2078668\ttotal: 1m 17s\tremaining: 4.66s\n",
      "943:\tlearn: -0.2075687\ttotal: 1m 17s\tremaining: 4.58s\n",
      "944:\tlearn: -0.2074374\ttotal: 1m 17s\tremaining: 4.5s\n",
      "945:\tlearn: -0.2068508\ttotal: 1m 17s\tremaining: 4.42s\n",
      "946:\tlearn: -0.2066010\ttotal: 1m 17s\tremaining: 4.33s\n",
      "947:\tlearn: -0.2064536\ttotal: 1m 17s\tremaining: 4.25s\n",
      "948:\tlearn: -0.2061395\ttotal: 1m 17s\tremaining: 4.17s\n",
      "949:\tlearn: -0.2058975\ttotal: 1m 17s\tremaining: 4.09s\n",
      "950:\tlearn: -0.2057784\ttotal: 1m 17s\tremaining: 4s\n",
      "951:\tlearn: -0.2053033\ttotal: 1m 17s\tremaining: 3.92s\n",
      "952:\tlearn: -0.2051271\ttotal: 1m 17s\tremaining: 3.84s\n",
      "953:\tlearn: -0.2050501\ttotal: 1m 17s\tremaining: 3.76s\n",
      "954:\tlearn: -0.2046049\ttotal: 1m 18s\tremaining: 3.68s\n",
      "955:\tlearn: -0.2042088\ttotal: 1m 18s\tremaining: 3.6s\n",
      "956:\tlearn: -0.2040171\ttotal: 1m 18s\tremaining: 3.51s\n",
      "957:\tlearn: -0.2037787\ttotal: 1m 18s\tremaining: 3.43s\n",
      "958:\tlearn: -0.2032861\ttotal: 1m 18s\tremaining: 3.35s\n",
      "959:\tlearn: -0.2030807\ttotal: 1m 18s\tremaining: 3.27s\n",
      "960:\tlearn: -0.2029501\ttotal: 1m 18s\tremaining: 3.19s\n",
      "961:\tlearn: -0.2028271\ttotal: 1m 18s\tremaining: 3.1s\n",
      "962:\tlearn: -0.2024578\ttotal: 1m 18s\tremaining: 3.02s\n",
      "963:\tlearn: -0.2017480\ttotal: 1m 18s\tremaining: 2.94s\n",
      "964:\tlearn: -0.2014682\ttotal: 1m 18s\tremaining: 2.86s\n",
      "965:\tlearn: -0.2011503\ttotal: 1m 18s\tremaining: 2.78s\n",
      "966:\tlearn: -0.2008412\ttotal: 1m 19s\tremaining: 2.7s\n",
      "967:\tlearn: -0.2004564\ttotal: 1m 19s\tremaining: 2.62s\n",
      "968:\tlearn: -0.2001422\ttotal: 1m 19s\tremaining: 2.53s\n",
      "969:\tlearn: -0.1999134\ttotal: 1m 19s\tremaining: 2.45s\n",
      "970:\tlearn: -0.1995601\ttotal: 1m 19s\tremaining: 2.37s\n",
      "971:\tlearn: -0.1993366\ttotal: 1m 19s\tremaining: 2.29s\n",
      "972:\tlearn: -0.1989176\ttotal: 1m 19s\tremaining: 2.21s\n",
      "973:\tlearn: -0.1985275\ttotal: 1m 19s\tremaining: 2.13s\n",
      "974:\tlearn: -0.1982931\ttotal: 1m 19s\tremaining: 2.04s\n",
      "975:\tlearn: -0.1980118\ttotal: 1m 19s\tremaining: 1.96s\n",
      "976:\tlearn: -0.1978549\ttotal: 1m 19s\tremaining: 1.88s\n",
      "977:\tlearn: -0.1974966\ttotal: 1m 19s\tremaining: 1.8s\n",
      "978:\tlearn: -0.1973023\ttotal: 1m 20s\tremaining: 1.72s\n",
      "979:\tlearn: -0.1967830\ttotal: 1m 20s\tremaining: 1.64s\n",
      "980:\tlearn: -0.1965310\ttotal: 1m 20s\tremaining: 1.55s\n",
      "981:\tlearn: -0.1962696\ttotal: 1m 20s\tremaining: 1.47s\n",
      "982:\tlearn: -0.1960457\ttotal: 1m 20s\tremaining: 1.39s\n",
      "983:\tlearn: -0.1956915\ttotal: 1m 20s\tremaining: 1.31s\n",
      "984:\tlearn: -0.1954025\ttotal: 1m 20s\tremaining: 1.23s\n",
      "985:\tlearn: -0.1951842\ttotal: 1m 20s\tremaining: 1.14s\n",
      "986:\tlearn: -0.1949361\ttotal: 1m 20s\tremaining: 1.06s\n",
      "987:\tlearn: -0.1946734\ttotal: 1m 20s\tremaining: 981ms\n",
      "988:\tlearn: -0.1945219\ttotal: 1m 20s\tremaining: 899ms\n",
      "989:\tlearn: -0.1941789\ttotal: 1m 20s\tremaining: 817ms\n",
      "990:\tlearn: -0.1939877\ttotal: 1m 21s\tremaining: 736ms\n",
      "991:\tlearn: -0.1937916\ttotal: 1m 21s\tremaining: 654ms\n",
      "992:\tlearn: -0.1936086\ttotal: 1m 21s\tremaining: 572ms\n",
      "993:\tlearn: -0.1935238\ttotal: 1m 21s\tremaining: 490ms\n",
      "994:\tlearn: -0.1933178\ttotal: 1m 21s\tremaining: 409ms\n",
      "995:\tlearn: -0.1930318\ttotal: 1m 21s\tremaining: 327ms\n",
      "996:\tlearn: -0.1928444\ttotal: 1m 21s\tremaining: 245ms\n",
      "997:\tlearn: -0.1926671\ttotal: 1m 21s\tremaining: 163ms\n",
      "998:\tlearn: -0.1925086\ttotal: 1m 21s\tremaining: 81.7ms\n",
      "999:\tlearn: -0.1921668\ttotal: 1m 21s\tremaining: 0us\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=12, objective='binary:logistic', random_state=42,\n",
      "       reg_alpha=0, reg_lambda=3, scale_pos_weight=0.8, seed=None,\n",
      "       silent=False, subsample=1)\n",
      "Before Num features= 15712 Counter({0: 1014, 1: 352, 2: 179, 3: 148, 4: 92})\n",
      "After Num features= 286\n"
     ]
    }
   ],
   "source": [
    "#list_of_model = ['decision_tree_classifier', 'gaussian', 'logistic_regression', 'MLPClassifier', 'RandomForestClassifier',\n",
    "#                 'SVC', 'Catboost', 'XGB_classifier']\n",
    "list_of_model = [ 'Catboost','XGB_classifier']\n",
    "\n",
    "for each_model in list_of_model:\n",
    "    model=get_model(m_type=each_model)\n",
    "    binny_classifier_run(X,y,model,each_model,label_map,img_name,report_name,save_model=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
